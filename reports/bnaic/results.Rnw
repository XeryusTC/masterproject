%!TeX root = ../main.Rnw

\section{Experimental results}\label{sec:results}
The proposed algorithms are tested and compared against the complete algorithm
OD+ID and the decentralized algorithm DiMPP (discussed in \autoref{sec:intro}). 
We compare them on a large set of
randomly generated problem instances. Each instance in the set consists of a
$16 \times 16$ 8-connected grid. Each grid cell has a $20\%$ chance of
containing an impassable obstacle as specified in \autoref{sec:problem}. Agents
are placed randomly in the grid such that no two agents have the same starting
position. Each agent is given a randomly chosen destination location.
These are picked in such a way that no two agents have the same
destination. Note that the starting position of one agent might be the
destination of another. There is a time limit of 2000ms to solve each problem
instance. This limit is arbitrary but it was picked to show representative
results. All experiments were implemented in Python 3.6 and ran
on a single core of an AMD FX-8120 clocked at 3.1GHz. Our main hypothesis is
that our proposed algorithms are able to solve more problem instances and are
able to find solutions faster than OD+ID is. We expect that OD+ID finds higher
quality paths. We expect our proposed algorithms perform on an equal 
or slightly worse level than DiMPP on all aspects.

Before being able to evaluate DPCA* we have to determine the weights that are
used during voting. To do this we used simulated annealing
\cite{kirkpatrick1983} with an initial temperature of 100 which drops to 1 in
unit steps. Each iteration of the simulated annealing process consists of 200
problem instances which contain between 2 and 50 agents. After each drop of
temperature we generate a new set of 200 problem instances to prevent
overfitting.
\autoref{tbl:annealing} shows the results of annealing.
%The results of annealing are shown in \autoref{tbl:annealing}.
The
path length weight measures the increase of path length; the conflicts solved
weight measures how many additional conflicts were solved by a proposal; and
the partial solution weight is used as a penalty so that proposals which solve
an instance by assigning minimal explicit priorities are preferred.

\begin{table}[t]
    \centering
    \caption{Evaluation weights as determined by simulated annealing. An empty
        field mean that the weight is not used by that algorithm.}
    \label{tbl:annealing}
    \begin{tabularx}{\columnwidth}{l|X|X|X}
        & Path length ($w_1$) & Conflicts solved ($w_2$) & Partial solution 
        ($w_3$) \\ 
        \hline
        \Sexpr{cannonical.names[3]} & 4.744 & 5.291 &  \\
        \Sexpr{cannonical.names[4]} & 0.312 & 5.570 & 2.677
    \end{tabularx}
\end{table}

<<perfgraph,echo=F,warning=F,cache=T,cache.beater=dat,dev='tikz',fig.height=2,fig.width=5,fig.align='center',fig.pos='t',fig.cap=perfgraph.title>>=
op <- par(mar = c(3.8, 3.8, 1, 1))
plot(c(),
    type='l',
    log='y',
    col='red',
    xlim=c(0,10000),
    ylim=c(10, 2000),
    xlab='Problem instance',
    ylab='Time (ms)',
    frame.plot=F,
    xaxt="n",
    yaxs="i", yaxt="n"
)
axis(1, at=seq(0, 10000, 1000),
     labels=c(0, "", 2000, "", 4000, "", 6000, "", 8000, "", 10000))
axis(2, at=c(10, 100, 1000, 2000), labels=c(10, 100, 2000, ""))
lines(seq(length(od)),    od,    col=color.set[1], lwd=linewidth,
	  lty=linetypes[1])
lines(seq(length(naive)), naive, col=color.set[2], lwd=linewidth,
      lty=linetypes[2])
lines(seq(length(base)),  base,  col=color.set[3], lwd=linewidth,
      lty=linetypes[3])
lines(seq(length(plus)),  plus,  col=color.set[4], lwd=linewidth,
      lty=linetypes[4])
lines(seq(length(dimpp)), dimpp, col=color.set[8], lwd=linewidth,
      lty=linetypes[8])
legend("bottomright",
       legend=cannonical.names[c(1:4,8)],
       col=color.set[c(1:4,8)],
       bty="n",
#       cex=.8,
       lwd=linewidth,
       lty=linetypes[c(1:4,8)])
@

To compare the algorithms we give them a set of 10000 problem instances which
have between 2 and \agentsupb agents. 
%The time required to solve each instance is recorded and sorted in ascending 
%order so that we can plot them in a \emph{performance 
%graph}~\cite{standley2010} as shown in  \autoref{fig:perfgraph}.
When we record the time required to solve each instance and sort them in 
ascending order we can plot them in a \emph{performance 
graph}~\cite{standley2010} as shown in \autoref{fig:perfgraph}.
The $x$-axis
shows the index of the sorted instance. It is not necessarily the case that the
$n$th instance for one algorithm is the same as that for a
different algorithm. The $y$-axis shows the time it takes an algorithm to solve
that instance. A lower line in the performance graph means that the algorithm
was able to solve instances faster. Instances that were not solved within the
2000ms time limit are not plotted, so the graph also indicates how
many instances were successfully solved by an algorithm. When a plot
extends further along the $x$-axis it means that the algorithm was able to
solve more instances. \autoref{fig:perfgraph} shows that PCA* is generally
slower than OD+ID. The latter was faster on $\Sexpr{round(naive.vs.odid *
100, 1)}\%$ of the instances that both algorithms solved.
DPCA* and DPCA*+ perform on a similar level. DPCA* is slightly faster on each
individual instance by $\Sexpr{signif(abs(base.vs.plus$estimate * 1000), 2)}$
ms as shown by a one-sided paired t-test $(t(\Sexpr{base.vs.plus$parameter}) =
\Sexpr{round(base.vs.plus$statistic, 2)}, p=\Sexpr{signif(base.vs.plus$p.value,
3)})$. Both algorithms perform similar to DiMPP until 2300 instances, after 
which DiMPP is slower.

<<solved,echo=F,cache=T,cache.beater=solved.aggr,dev='tikz',fig.width=5,fig.height=2,fig.align='center',fig.pos='t',fig.cap=solved.title>>=
op <- par(mar = c(4, 3.8, 1, 1))
plot(c(),
    type='l',
    xlim=c(0,40),
    ylim=c(0,1),
    xlab='Agents in problem instance',
    ylab='Percentage solved',
    frame.plot = F,
    yaxs="i", yaxt="n",
    xaxs="i", xaxp=c(0, 40, 8)
)
axis(2,
     at=c(0, 0.25, 0.5, 0.75, 1),
     labels=c("0\\%", "", "50\\%", "", "100\\%"))
for(i in c(1:4,8)) {
    lines(solved.aggr[solved.aggr[,1]==algorithms[i],]$time,
        col=color.set[i], lty=linetypes[i], lwd=linewidth)
}
legend("topright",
       legend=cannonical.names[c(1:4,8)],
       col=color.set[c(1:4,8)],
       bty="n",
#       cex=.8,
       lwd=linewidth,
       lty=linetypes[c(1:4,8)])
@

<<quality,eval=F,echo=F,cache=T,cache.beater=solved,results='asis'>>=
quality.table = t(rbind(paste(round(solved$time * 100, 1), "%"),
                        round(lengths$length, 2)))
colnames(quality.table) = c('Instances solved', 'Length')
rownames(quality.table) = cannonical.names
xtable(quality.table[c(1:4,8),],
       label='tbl:quality',
       caption='Solution quality of algorithms. Length is the sum of the lengths
       of the paths for a single problem instance.',
       align='l|r|r',
       digits=2
)
@

<<lengths,echo=F,warning=F,cache=T,cache.beater=dat.lengths,dev='tikz',fig.width=5,fig.height=2,fig.align='center',fig.pos='t',fig.cap=lengths.title>>=
op <- par(mar = c(4, 3.8, 1, 1))
plot(c(),
     type='n',
     xlim=c(5,40),
     ylim=c(100,350),
     frame.plot=F,
     xaxs="i", yaxs="i",
     xlab='Agents in problem instance',
     ylab='Sum of path lengths',
     yaxs="i", yaxt="n",
     xaxs="i", xaxp=c(0, 40, 8)
)
axis(2, at=seq(100, 350, 50))
for (i in c(1:4,8))
{
    lines(dat.lengths[dat.lengths[,2]==algorithms[i],]$length, col=color.set[i],
    lwd=linewidth, lty=linetypes[i])
}
legend("topleft",
       legend=cannonical.names[c(1:4,8)],
       col=color.set[c(1:4,8)],
#       cex=.8,
       bty='n',
       lwd=linewidth,
       lty=c(1:4,8))
@

\autoref{fig:solved} shows how many instances each algorithm can solve within
the time limit for varying number of agents in an instance. It shows a
similar picture as \autoref{fig:perfgraph} where OD+ID and PCA* solved only few
instances while DPCA* and DPCA*+ are able to solve problems that include more
agents. DiMPP falls in between these two groups. \autoref{fig:lengths} 
shows how long the paths found by each algorithm are. In general DPCA* and 
DPCA*+ find longer paths than OD+ID. DiMPP causes the largest detours of all 
tested algorithms. PCA* finds the shortest paths of all algorithms.

<<dialogues,echo=F,warning=F,cache=T,cache.beater=conflicts.aggr,dev='tikz',fig.width=5,fig.height=2,fig.align='center',fig.pos='t',fig.cap=conflicts.title>>=
op <- par(mar = c(4, 3.8, 1, 1))
plot(1,
    type='l',
    xlim=c(0,40),
    ylim=c(0,30),
    xlab='Agents in problem instance',
    ylab='Dialogues',
    frame.plot = F,
    yaxs="i",
    xaxs="i", xaxp=c(0, 40, 8)
)
for(i in c(2:4))
{
    lines(conflicts.aggr[conflicts.aggr[,1]==algorithms[i],]$solved.conflicts,
      col=color.set[i], lty=linetypes[i], lwd=linewidth)
}
legend("topleft", legend=cannonical.names[2:4], col=color.set[2:4],
    bty="n",
#    cex=.8,
    lwd=linewidth,
    lty=linetypes[2:4])
@

The average number of dialogues that have taken place to find a solution is
shown in \autoref{fig:dialogues}. It shows that more dialogues are needed when
the problem instance contains more agents. DPCA* and DPCA*+ need a similar
amount of dialogues, and they need a large amount more than PCA*.
One thing of note is that the number of dialogues required
rises when the number of agents increases, but at some point this
trend trails off. This point lies around 15 agents for PCA* and around 25
agents for DPCA* and DPCA*+.

<<conflict-sizes,echo=F,cache=T,cache.beater=sizes.aggr,dev='tikz',fig.width=5,fig.height=2,fig.align='center',fig.pos='t',fig.cap=sizes.title>>=
op <- par(mar = c(4, 3.8, 1, 1))
plot(1,
    type='n',
    xlim=c(1,40),
    ylim=c(0,15),
    xlab="Agents in problem",
    ylab="Agents in conflicts",
    xaxs="i", yaxp=c(0, 15, 3),
    yaxs="i", xaxp=c(0, 40, 8),
    frame.plot = F
)
points(sizes.aggr$X3, col='blue', pch=4)
points(sizes.aggr$X4, col='green', pch=3)
points(sizes.aggr$X2, col='red', pch=8)
lines(smooth.spline(sizes.aggr$X3, spar=0.35), col="blue", lwd=linewidth)
lines(smooth.spline(sizes.aggr$X4, spar=0.35), col="green", lwd=linewidth)
lines(smooth.spline(sizes.aggr$X2, spar=0.35), col="red", lwd=linewidth)
legend("topleft",
       legend=c('2 agents', '3 agents', '4 agents'),
       col=c("red", "blue", "green"),
       pch=c(8, 4, 3),
       bty='n')
@

Results for DPCA* and DPCA*+ are rather close in the above graphs.
\autoref{fig:conflict-sizes} shows how many agents participate in DPCA*+
dialogues. It shows that most dialogues involve just two agents. There are on
average $\Sexpr{signif(max(sizes.aggr$X3), 3)}$ dialogues per instance with
three agents, and only $\Sexpr{signif(max(sizes.aggr$X4), 3)}$ with
four agents.
DPCA*+ uses a more complex conflict solving strategy than DPCA* while it does 
not have to solve more complex dialogues.
%DPCA*+ often does not have to solve more complex dialogues than DPCA* but it 
%does use a more complex strategy and thus it is slightly slower.

<<cache,echo=F,warning=F,cache=T,cache.beater=dat.cache,dev='tikz',fig.width=5,fig.height=2,fig.align='center',fig.pos='t',fig.cap=cachegraph.title>>=
op <- par(mar = c(3.8, 3.8, 1, 1))
plot(c(), c(),
     type='l',
     log='y',
     col='red',
     xlim=c(1,len.cache),
     ylim=c(10, 2000),
     xlab='Instance',
     ylab='Time (ms)',
     frame.plot=F,
     xaxp=c(0, 1000, 10),
     yaxs="i", yaxt="n"
)
axis(2, at=c(1, 10, 100, 1000, 2000), labels=c(1, 10, 100, 2000, ""))
lines(seq(length(plus.nocache)), plus.nocache, lty=3,
      lwd=linewidth)
lines(seq(length(plus.cache)), plus.cache, lty=1,
      lwd=linewidth)

legend("bottomright",
       legend=c("Cache disabled", "Cache enabled"),
       lwd=linewidth,
       lty=c(3, 1),
       bty="n",
#       cex=.8
       )
@

There should be a noticeable decrease in the time it takes to solve a problem 
when the agents use a path cache.
To measure the effect of caching on 
solving cooperative pathfinding problems we conducted a separate experiment of 
1000 problem instances that were solved with the path cache enabled and 
disabled. All other parameters were the same as in previous 
experiments. The result of this experiment is shown in \autoref{fig:cache}. We 
do 
not show the results for DPCA*+ because they are identical to those of DPCA*. 
The figure shows that after the initial 80 problem instances the path cache 
does decrease the time required to find a solution. Using the cache also 
results in DPCA* being able to solve more problem instances within the time 
limit.