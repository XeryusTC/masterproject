\section{Algorithm}\label{sec:method}
Decoupled algorithms are able to solve cooperative pathfinding problems while
requiring only minimal resources. The agents calculate paths to their
destination individually so this is inherently distributed. To achieve this
there has to be determine a  priority order for the agents so that they can
plan paths that have no conflicts. To do this there is often a central
processor that knows the optimal paths of all agents. This central processor
can then
find dependencies between agents to determine possible priority orderings that
can be used to solve the problem \cite{latombe1991,bennewitz2002}. This means
that decoupled methods are almost fully distributed but they have a single
centralized bottleneck. All agents will have to halt calculating a solution
while the priority scheme is determined by the central processor.

To overcome this bottleneck the calculation of the priority ordering can also
become distributed. The three step base decoupled method can be
altered to allow for this, the first step where each agent plans its optimal
path without regard for the other agents remains the same. Next agents share
the paths that they found with each other. Each agent can now determine where
its path and the paths of other agents
have conflicting moves that would lead to a collision. The agents will then be
able to solve the conflicts without having to wait for slower agents to
calculate and communicate their optimal paths. To solve conflicts agents will
start a dialogue where possible solutions are proposed, evaluated and adapted.
The proposals made consist of a priority order for the agents involved in the
conflict. Agents will only need to solve the first conflict that occurs in
their path because solving it may have the side-effect of solving later
conflicts. After a conflict has been successfully solved then the agents
involved can work on solving the next conflict.
Below are the details of three different versions of this algorithm, each
version of the algorithm has some improvements over the previous version.

%Each of the three algorithms builds upon a more general search algorithm
%Cooperative A* (CA*). This algorithm is a variation on A* \cite{hart1968} that
%allows teams of agents to cooperate. Each agent searches for a path
%individually, but they can take each other's actions into account. Both space
%and time are searched so that the movements of other agents can be considered.
%Agents send their paths to the other agents once they're found. During the
%neighbouring node expansion stage of A*

\subsection{Partial Cooperative A*}
The heart of the algorithm is the conflict resolution step. The most
straightforward approach to solving conflicts is by going through all possible
agent orderings. An ordering determines which agent has priority over another
agent, the ordering $a_1 > a_2$ indicates that $a_1$ can plan freely while
$a_2$ has to consider $a_1$ as a moving obstacle. Usually decoupled methods use
a permutation of the priority ordering $a_1 > a_2 > \ldots > a_k$ that all
agents have to adhere to. Partial Cooperative A* (PCA*) uses the method
described above to allow agents to communicate conflicts with each other. When
agents detect that they have a conflict they will try to find a priority
ordering between them that will solve the conflict. Agents will always try to
find a solution to the conflict that is closest to their current position
first. This is because the solution to earlier occurring conflicts may also
have the effect of solving or creating later conflicts.

To find the most suitable priority ordering scheme all possible orderings
between the agents that are involved in the conflict are evaluated. So a
conflict with two agents will result in the ordering $a_1 > a_2$ and $a_2 >
a_1$. The agents temporarily adapt the first ordering and plan new paths with
the constraints it introduces, the agents measure the length of the paths that
they found. Next they will adapt the second ordering and create a new plan
using its constraints, they also measure the lengths. The priority scheme for
which the sum of the path lengths is the lowest is permanently adapted by the
agents. Because the solution with the lowest sum path length is used there is
no consideration for the effects of the solution of conflicts that occur later.

Only the agents that occur in a priority ordering adapt it. This means that an
agent $a_3$ does not know about the ordering that agents $a_1$ and $a_2$ have
settled on, say that they picked $a_2 > a_1$. When $a_3$ and $a_1$ have a
conflict then this will also find a solution to it. If they settle on a
solution $a_1 > a_3$ then only $a_1$ knows $a_2 > a_1 > a_3$, the other two
agents only know the partial priorities. In this case the global priority is
known by $a_1$, but it will not always be the case that one agent knows the
full priority ordering. The ordering is implied by the partial orderings that
the agents do know about, this is similar to how plans are constructed in
partial global planning.
% TODO: incremental plans

The orderings that are found do not need to be unambiguous, if $a_1$ and $a_3$
had used the solution $a_3 > a_1$ then $a_1$ would have orderings $a_2 > a_1$
and $a_3 > a_1$ but no $a_2 > a_3$ or $a_3 > a_2$. This leaves $a_2$ and $a_3$
free to use any priority scheme in the event that they also have a conflict in
their paths. This also allows for circular priority orderings, something which
conventional decoupled algorithms do not support. This is possible because the
circular ordering is implicit in all the partial orderings that individual
agents know about. The implied global priority also doesn't need to be
complete, not every agent needs to be present in it. This is easiest to see
when considering only agents $a_1$ and $a_5$ in \autoref{fig:world}, for this
example the other agents do not exist. There is no need to establish an
ordering for these two agents since their paths never meet. This has the effect
of implied Independence Detection \cite{standley2010} because these agents will
never have to communicate beyond sharing the paths that they have found with
each other. There is no need for them to coordinate because their plans never
interact.
% Simplicity of algorithm b/c not able to predict consequences
% priorities form PGP

%The simplest approach to resolving the conflicts is by creating all possible
%ordering permutations for the agents involved in the conflict. The permutation
%that has the lowest sum path length is used as the solution for the conflict.
%This simple method of evaluating the various solutions is unlikely to find the
%most appropriate one because it is not able to predict the consequences of
%selecting one solution over the others.
%Most conflicts involve just two agents, so there are only two possible ordering
%permutations which means that the amount of priority permutations that need to
%be evaluated is low.

\subsection{Dialogue-based Partial Cooperative A*}
\begin{table}
    \centering
    \caption{Stages of a conflict resolution dialogue.}
    \label{tbl:stages}
    \begin{tabular}{l|l|l}
        Stage & Goal & Next stage \\ \hline
        Opening & Exchange information & Proposal \\
        Proposal & Make (incomplete) priority proposals & Evaluation \\
        Evaluation & Vote on suitability of proposals & Proposal, Closing \\
        Closing & Permanently adapt best proposal & \\
    \end{tabular}
\end{table}

Going through all possible permutations and evaluating them on a single
criterion is not the most clever method of finding a priority ordering
\cite{bennewitz2002}. This would mean that the entire search space is
exhaustively examined until a working solution is found. To avoid evaluating
all possible permutations and thereby reducing the time required to find a
solution some improvements can be made. Utilising a dialogue to solve conflicts
can reduce the number of priority combinations that need to be evaluated.
Agents take part in a dialogue of which the goal is to find a solution to the
conflict that works for all agents involved in the conflict. This dialogue
consists of several stages which are summarised in \autoref{tbl:stages}. For
each conflict the agents start a new dialogue. The agents work through the
conflicts in chronological order, they solve conflicts that occur early before
solving conflicts that occur later. The opening stage is where each dialogue
starts, during this stage the agents notify each other if they are taking part
in any dialogues for conflicts that occur earlier than the current conflict
being discussed. If there is such a prior dialogue then the current dialogue
will be put on hold all earlier dialogues are completed. If the conflict that
the dialogue is on is the earliest conflict for all involved agents then the
dialogue moves on to the proposal stage.

During the proposal stage each agent can enter a new ordering proposal that is
to be evaluated. Agents can make only one single proposal during each proposal
stage. There can be multiple of these stages during a dialogue so it is
possible for agents to make multiple proposals before the dialogue has
concluded. The proposed priority can be
partial, if there are three or more agents taking part of the dialogue then
$a_1 > a_2 > a_3$ is a valid proposal but $a_1 > a_2, a_3$ is as well. In the
latter case $a_1$ has priority over both $a_2$ and $a_3$, but there is no
established priority ordering between $a_2$ and $a_3$ yet and this may be
decided upon later during the dialogue, or during a future dialogue. Agents
will always propose that they get a higher priority over the other agents that
are part of the conflict. So in a dialogue that involves two agents $a_4$ and
$a_5$ each agent gets to make a proposal, $a_4$ will propose $a_4 > a_5$ while
$a_5$ will propose $a_5 > a_4$.

The third stage is the evaluation stage which is reached when all agents have
made a proposal or declined to make one. Each of the new proposals will be
evaluated in turn. To evaluate a proposed priority ordering the agents adapt it
and update their plans. During this replanning agents have to take into account
the constraints imposed by both the ordering in the proposal, and the ordering
imposed by previously solved conflicts. Once an agent has updated its plan then
it will cast a vote based on how suitable the proposal is. When an agent finds
that it is unable to plan a path to its destination under a certain proposal
then it will notify the other agents of this. In this case the proposal is
rejected by all agents and not voted on, it can also not be expanded on during
an extra proposal stage. If it is not the case that an agent is blocked from
reaching its destination then all agents will vote on their preference for a
proposal. Each vote consists of a single real number that represents how
suitable the proposal is. This number is based on the increase of the length of
the path, and whether the new plan solves or causes more conflicts at later
time steps. Both of these factors are weighted to result in the final vote. All
agents cast a vote on each acceptable proposal. The proposal with the highest
sum of the votes is accepted as the solution to the conflict. The votes of each
agents are weighted equally, so there is no agent which has a stronger vote.

After all the proposals have been evaluated there is room for agents to claim
to want to make additional proposals. If an agent does so then the dialogue
goes through another proposal and evaluation stage. If no agent wants to make
additional proposals the dialogue can be completed in the closing stage. During
the closing stage each agent will permanently adapt the priority scheme with
the highest sum of votes. The priority ordering in this proposal is always
considered when making new proposals and plans during future dialogues. This
completes the dialogue, the agents can now work on conflicts that still occur.
The entire above process is repeated for all conflicts until they are all
solved.

In conflicts that involve three or more agents it is not always the case that a
priority ordering will solve the conflict for all agents. In some conflicts
involving agents $a_1, a_2, a_3$ it may be the case that a partial ordering
$a_1 > a_2, a_3$ means that $a_1$ will not have a conflict with $a_2$ and $a_3$
any more, but that $a_2$ and $a_3$ will still have a conflict at another
position and/or time. In this case either agent can make a request for an
additional proposal round. During this proposal round the agents can make new
proposals or expand on additional proposals. Agents do not need to make
proposals so $a_1$ might not make any new proposals because it already has the
highest priority in the proposal $a_1 > a_2, a_3$. On the other hand $a_2$ and
$a_3$ are likely to make proposals, they could make the proposals $a_1 > a_2 >
a_3$ and $a_1 > a_3 > a_2$ respectively. After all three agents have entered a
proposal or declined to make one the dialogue moves to the evaluation stage
again. This time only the new proposals are evaluated.
% should not accept expanded proposals

%After each evaluation stage the agents will tell each other whether they want
%to make additional proposals. If none of the agents does so then the dialogue
%moves to the closing stage.

% additional proposal stages
% multiple agents
% Closing stage

%During the evaluation of a proposal each agent has to update
%their plan, the restrictions imposed by the ordering of the proposal should be
%respected, as well as the restrictions imposed by previously solved conflicts.
%Once an
%agent is done with updating its plan then it will cast a vote based on how
%suitable the proposal is. All votes are collected and the best proposal is
%used as the solution. It is also possible that an agent was blocked from
%reaching its destination with the proposed priorities, in this case an agent
%can also notify the other agents of this and the proposal is rejected.
%
%When multiple agents are involved then it is possible that a proposal can not
%be solved by giving one agent priority over all the others, in this case a more
%complete priority ordering is required. If this happens then the dialogue will
%have another proposal stage. Agents will now be allowed to expand on earlier
%proposals as well as making completely new proposals. Afterwards there is
%another evaluation stage.
%
%After each evaluation stage the agents will tell each other whether they want
%to make additional proposals. If none of the agents does so then the dialogue
%moves to the closing stage. During the closing stage the proposal with the most
%votes is selected as the solution for the conflict. All agents that took part
%in the dialogue permanently adapt the priority ordering. After the dialogue is
%finished the agents will start working on resolving any further conflicts that
%they may have. As a result of resolving conflict agent's plans may have been
%changed, so they will have to communicate their updated plans to the other
%agents, they will also have to recalculate where and when conflicts in their
%plans occur.

There are two approaches to solving conflicts that involve multiple agents. The
first is to have a single dialogue for all agents, this is referred to as
Dialogue-based Partial Cooperative A* Plus (DPCA*+). Another approach is to let
agents solve conflicts in pairs only. If there is a conflict between agents
$a_1$, $a_2$, $a_3$ at time $t$ then there would be three dialogues: one
between $a_1$ and $a_2$, one between $a_1$ and $a_3$, and one between $a_2$ and
$a_3$. Say $a_1$ and $a_2$ are first to hold a dialogue which finishes with the
priority $a_1 > a_2$, meaning that $a_1$ has priority over $a_2$. $a_2$ is then
routed away from the conflict location. Next $a_1$ and $a_3$ will have to
resolve their remaining conflict. When this is also resolved as $a_1 > a_3$
then the conflict at $t$ is solved. It may be the case that $a_2$ and $a_3$ now
have a conflict at another position and they will have to solve this as well.
This algorithm is called Dialogue-based Partial Cooperative A* (DPCA*). This
approach of having multiple smaller dialogues can be faster than having a
single large complex dialogue.

Each time that agents evaluate a proposal they have to compute paths that
satisfy the constraints imposed by the priority orderings. This often means
that agents have to recompute the same paths when their priority doesn't change
between proposals. Te reduce the amount of computation required agents can
store the paths that they have calculated. When agents need to calculate a path
to evaluate a proposal they can consult their path cache. This allows them to
use a path that has been found earlier and use that as a solution. The only
restriction is that the cached path does not have a conflict with the paths of
agents that have a higher priority. Some cached paths may cause new additional
conflicts with lower priority agents. This should not stop agents from using
this path because they can solve these conflicts in a later dialogue. Using a
cache should reduce the overall amount of time that is required to find a
conflict free set of paths for all agents.

\begin{figure}
    \centering
    \begin{subfigure}[t]{.3\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/dialogue-example-initial.pdf_tex}
        \caption{Initial configuration.}
        \label{fig:example-initial}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{.3\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/dialogue-example-prop1.pdf_tex}
        \caption{Configuration after proposal $a_2 > a_1$.}
        \label{fig:example-prop1}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{.3\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/dialogue-example-solution.pdf_tex}
        \caption{Configuration after proposal $a_1 > a_2$.}
        \label{fig:example-solution}
    \end{subfigure}
    \caption{Three stages of resolving a conflict. Agents are circles inscribed
    by $a_i$, their respective goals are $g_i$. Paths that are followed are
    indicated by the arrows. The red dot represent where two paths have
    conflicting moves.}
    \label{fig:example}
\end{figure}

\paragraph{Example of conflict resolution} Consider the cooperative pathfinding
problem in \autoref{fig:example-initial}. It shows a $4 \times 4$ grid with
three agents in it and the initial optimal paths they find during the first
step of the algorithm. Agent $a_1$ has a path that consists of three
\emph{south} moves, $p_{a_{1},1} = \{\text{\emph{south, south, south}}\}$,
while both $a_2$ and $a_3$ have paths that consist of three consecutive
\emph{east} moves, $p_{a_2,1} = p_{a_3,1} = \{\text{\emph{east, east,
east}}\}$. No agents have a \emph{wait} move on their path. All three
agents share their paths with each other, agents $a_1$ and $a_2$ discover that
they have a conflict after their first action. This means that they will have
to resolve this situation so that they will not collide. They start a dialogue
in its initial stage, the opening. All messages are broadcast to all agents in
the conflict dialogue, in this case $a_1$ and $a_2$:
\\ \-\qquad $a_1$: no earlier conflicts
\\ \-\qquad $a_2$: no earlier conflicts

Because both agents don't have any conflicts that occur at an earlier time
(this is time step 1) the dialogue continues to the proposal stage. Both agents
propose to go first:
\\ \-\qquad $a_2$: propose $a_2 > a_1$
\\ \-\qquad $a_1$: propose $a_1 > a_2$

Both agents have made a proposal to resolve the conflict so the dialogue can
move towards the evaluation stage. Because $a_2$ entered a proposal before
$a_1$ its proposal will be evaluated first. Agent $a_2$ has the highest
priority so its path doesn't need to change so its path remains $p_{a_2,1}$. It
sends its new path to $a_2$:
\\ \-\qquad $a_2$: new path $p_{a_2,1} = \{\text{\emph{east, east, east}}\}$

Agent $a_1$ does have to yield to $a_2$ so it will have to consider possible
conflicts that arise with $p_{a_2,1}$ and plan around them. It finds a new path
$p_{a_1,2} = \{\text{\emph{south east, south, south west}}\}$ which is shown in
\autoref{fig:example-prop1}. After finding the new path $a_2$ will evaluate its
quality, to do this it will have to look at the new length of the path and
whether any new conflicts were introduced. Say that the influence of the change
in path length has a weight of 1 while the introduction of conflicts has a
weight of 3. The agent had one conflict before the dialogue and it has a new
conflict with $a_3$ after planning the new path so there is no change in the
number of conflicts that $a_1$ is involved in, or $\Delta c = 0$. It can send
its evaluation to $a_2$:
\\ \-\qquad $a_1$: new path $p_{a_1,2} = \{\text{\emph{south east, south,
south west}}\}$
\\ \-\qquad $a_1$: $\eval(a_1, a_2 > a_1) = 1 \cdot (|p_{a_1,2}| - |p_{a_1,1}|)
+ 3
\cdot \Delta c = 0$

where $|p_{a_i,j}|$ is the number of actions in the $j$th path of
$a_i$. The evaluation of proposal $a_2 > a_1$ by $a_1$ is similar to how $a_2$
did its evaluation, but $a_1$ has one fewer conflict so $\Delta c = -1$:
\\ \-\qquad $a_2$: $\eval(a_2, a_2 > a_1) = 1 \cdot (|p_{a_2,1}| - |p_{a_2,1}|)
+ 3
\cdot \Delta c = -3$

Now that this proposal has been evaluated by both agents they can find the sum
score of the proposal which is $\eval(a_2 > a_1) = \eval(a_1, a_2 > a_1) +
\eval(a_2, a_2 > a_1) =
-3$. Next the agents can evaluate $a_1 > a_2$. When agent $a_1$ goes to
evaluate this conflict if finds that it can use the path $p_{a_1,1}$ which is
stored in its cache. It can use this because it has a priority scheme similar
to the one being evaluated; $a_1$ does not have to yield to any agent. It
notifies $a_2$ of this:
\\ \-\quad $a_1$: new path $p_{a_1,1} = \{\text{\emph{south, south, south}}\}$

Next $a_2$ can evaluate the proposal. First it needs to plan a new path that
does not conflict with the path that $a_1$ has just send. It finds the path
$p_{a_2,2} = \{\text{\emph{north easth, east, south east}}\}$. The new
situation is shown in \autoref{fig:example-solution}. It can
immediately evaluate it, the lengths of $p_{a_2,1}$ and $p_{a_2,2}$ are equal
and $a_1$ has one fewer conflicts so $\Delta c = -1$.
\\ \-\quad $a_2$: new path $p_{a_2,2} = \{\text{\emph{north easth, east, south
east}}\}$
\\ \-\quad $a_2$: $\eval(a_2, a_1 > a_2) = 1 \cdot (|p_{a_2,2}| - |p_{a_2,1}|)
+ 3 \cdot \Delta c = -3$

Agent $a_1$ can also send its evaluation to $a_2$:
\\ \-\quad $a_1$: $\eval(a_1, a_1 > a_2) = 1 \cdot (|p_{a_1,1}| - |p_{a_1,1}|)
+ 3 \cdot \Delta c = -3$

Now both agents have evaluated the proposal $a_1 > a_2$ they can find the sum
of the evaluations which is $\eval(a_1 > a_2) = \eval(a_1, a_1 > a_2) +
\eval(a_2, a_1 > a_2) =
-6$. All proposals have been evaluated so the agents can notify each other if
they want to make more proposals:
\\ \- \quad $a_1$: no more proposals
\\ \- \quad $a_2$: no more proposals

Neither agent wants to make more priority ordering proposals, this is because
there are no more possible priority orderings to make with these two agents.
The dialogue can then move to the closing stage. In the closing stage agents
will pick the best proposal, in this case that is the proposal with the lowest
sum score which is the proposal $a_1 > a_2$. To adapt this proposal agents will
need to use the respective paths that they used during the evaluation of the
proposal. So $a_1$'s path will be $p_{a_1,1}$ while $a_2$'s path will be
$p_{a_2,2}$. They also need to keep track of which agents have a higher
priority than themselves. For agent $a_1$ nothing changes, while $a_2$ must now
store that $a_1$ has a higher priority than it. All conflicts in
\autoref{fig:example} have now been solved and agents are free to execute their
paths.

\subsection{Windowed Dialogue-based Partial Cooperative A*}
One of the issues with this algorithm is that all dialogues and computation
occur before execution of the plan. Because both planning and execution take
time without requiring the same resources it is also possible to do them at the
same time. This means that the plan can be executed while it is still being
constructed. One way of doing this is my applying a window to DPCA*. A
window $w$ determines that agents will use the above algorithm to solve all
conflicts that occur within $w$ time steps from their current position. Agents
will not coordinate past the boundary of the window, solving conflicts that
happen beyond that border is deferred to a later point in time. Periodically
the agents will move their window and solve any new conflicts in the window.
Because agents only coordinate in the window it is not necessary for them to
plan a path past the window boundary as well. Instead agents can plan a path
for the next $w$ time steps so they get closer to their goal. To achieve this
the graph can be changed so that the nodes at the window boundary connect
directly to the goal node. This can be achieved by changing the cost function
between adjacent nodes $P$ and $Q$ \cite{silver2005}
\[
\text{\textsc{cost}(P,Q)} =
\begin{cases}
    0 & \text{if } P = Q = G, t < w \\
    \textsc{HeuristicDistance(P,G)} & \text{if } t = w \\
    1 & \text{otherwise}
\end{cases}
\]

Using the window spreads out the computation over the course of execution, but
it has other benefits as well. In large multi-agent systems the communication
between all agents may take a long time, by limiting the search using a window
there are only a limited number of agents that need to coordinate. This reduces
the initial planning time, as well as for each subsequent window. Agents that
are never in each other's window will never have to communicate with each other,
saving a lot of unnecessary communication and conflict detection overhead.
Windowing the search also has benefits in systems where agents can change their
destination during execution. Instead of recalculating the entire plan when
this happens, only agents within the window of the agent changing destination
have to update their plan. Agents that are not affected by the change in
destination do not have to update their plan. When there would be no window all
agents would have to recalculate and solve all conflicts again, even if they
would not need to update their plan, leading to wasted computational resources.

An overview of all proposed algorithms is given in \autoref{tbl:proposed}, the
categories shown are similar to those in \autoref{tbl:planning-overview}. All
methods are decoupled, not complete and do use priorities to ensure that agents
do not have conflicts. The meaning of communication has slightly changed, it
now restricts with which agents dialogues can be started.

\begin{table}
    \centering
    \caption{Comparison of proposed cooperative pathfinding algorithms. The
    communication and online columns are similar to that in
    \autoref{tbl:planning-overview}.}
    \label{tbl:proposed}
    \begin{tabular}{l|l|l|l}
        Algorithm & Na\"ive & Communication & Online \\ \hline
        PCA*   & Yes & All & No \\
        DPCA*  & No  & All & No \\
        WDPCA* & No  & Window & Yes \\
    \end{tabular}
\end{table}