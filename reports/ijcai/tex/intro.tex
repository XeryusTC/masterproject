\section{Introduction}\label{sec:intro}
When multiple agents have to find their way through a
shared space (\autoref{fig:world}), they have to find paths
around obstacles while they also need to ensure that they do not collide with
each other. Even when agents can prevent collisions it is still possible
that congestions and deadlocks occur. Some form of coordination between 
agents is needed to avoid such undesirable situations. This coordination problem has been 
referred to as cooperative pathfinding, or multi-agent pathfinding. It is 
encountered in robotics, aviation, road traffic management, crowd simulations, 
and video games.

\begin{figure}[t]
    \centering
    \def\svgscale{.5}
    \input{images/world.pdf_tex}
    \caption{An environment shared by multiple agents. Obstacles are black,
        agents are circles inscribed with the agent's number ($a_i$). The 
        destination for agent $a_i$ is given by $g_i$.}
    \label{fig:world}
\end{figure}

A straightforward but computationally inefficient solution to the problem is to 
search the Cartesian products of the state spaces of the individual 
agents~\cite{hopcroft1984}. Alternative algorithms for cooperative pathfinding 
are typically either \emph{centralized} or \emph{decoupled}~\cite{latombe1991}.
\emph{Centralized} algorithms try to control the state space explosion by 
efficiently calculating paths for each agent individually on a single 
processor. One example is Operator Decomposition and Independence Detection 
(OD+ID)~\cite{standley2010,standley2011} in which actions are assigned to agents. 
This algorithm is both complete and 
optimal: it will always find a solution to the problem if one exists, and this 
solution will be of minimal cost.
Another centralized method is the Increasing Cost Tree 
Search (ICTS) \cite{sharon2013} which searches combinations of increasingly 
longer paths for all agents. ICTS is faster than OD+ID in situations when the 
number of agents relative to the number of nodes is high.
In \emph{decoupled} algorithms each agent individually finds an optimal path 
for itself. Conflicts can for instance be resolved by imposing a priority 
ordering on the agents, where agents with a higher priority are considered 
moving obstacles~\cite{bennewitz2002}.
In decoupled approaches agents calculate their path on their own processor, but finding the priority ordering is done on a central 
processor. This 
approach is taken by Interruptible Asynchronous Decentralized Path Planning 
(IADPP)~\cite{cap2012}.
In these examples planning and execution are separated. In contrast online algorithms 
interleave planning and execution. For instance Windowed Hierarchical Cooperative A* 
(WHCA*)~\cite{silver2005} is a decoupled algorithm that employs a moving time window limiting the 
conflicts an agent takes into account while planning and replanning. This 
algorithm has been successful in the gaming industry.
Whereas centralized algorithms perform all calculations on a central processor and decoupled algorithms still use a central processor for determining the priority ordering, \emph{decentralized} algorithms use no central processor at all, as for instance Decentralized 
Multi-Robot Cooperative Pathfinding (DMRCP)~\cite{wei2016} and Distributed 
Multi-agent Path Planning (DiMPP) \cite{chouhan2017}.

% Argumentation
In the present paper we propose decentralized algorithms for cooperative 
pathfinding in which agents engage in a problem solving dialogue when they 
encounter a conflict. In this way, agents gradually adapt their individual 
plans to arrive at a globally coherent solution. We use ideas developed in 
computational argumentation~\cite{rahwanSimari2009} and in multi-agent 
coordination~\cite[pp.~202--204]{wooldridge2009}.

Computational argumentation has developed from the non-monotonic logics studied 
in Artificial Intelligence~\cite{dung1995} and has been applied in expert 
systems, multi-agent systems and law~\cite{vanEemerenEtal2014ch11}. Early work in 
computational argumentation studied individual planning~\cite{pollock1995} and 
more recently also multi-agent planning has been 
addressed~\cite{ferrando2012,pardo2011}. Our agents engage in a deliberation 
dialogue aimed at finding a plan of action. Deliberation dialogues are one of 
the argumentative dialogue types distinguished by Walton and 
Krabbe~\shortcite{walton1995} and have been studied by 
\cite{mcburney2007,walton2014}. We build specifically on the \textsc{TeamLog} model by~\shortcite{dunin-keplicz2011}.

% PGP
Multi-agent coordination is needed when the actions of agents can interact.
Wooldridge~\shortcite[pp.~202--204]{wooldridge2009} distinguishes several 
approaches to address multi-agent coordination, including Partial Global 
Planning (PGP)~\cite{durfee1991}. Nodes create their individual plans without 
regard for each other. They will then exchange information on their plans and
adapt them to coordinate their activities by incrementally 
adapting their plans to those of other agents.
%Coordination is not rigid and
%nodes are free to change their plan when circumstances change without the need 
%to re-coordinate with the other nodes. None of the involved nodes ever has a 
%global view, but the end result is a plan that is globally well
%coordinated with each node holding the part of the global plan that is relevant
%to it.
Generalized PGP \cite{decker1992} extends PGP beyond the application domain of sensory networks %with real-time planning, 
negotiation and coordination relationships between goals. 
% describe how to combine these three views

In this paper, deliberation dialogues are used in cooperative pathfinding by applying techniques from
partial global planning. Agents resolve conflicts by starting a dialogue in
which they share and evaluate different hypotheses to solve the conflict. A
hypothesis consists of a priority ordering for the agents that are involved in
the conflict. The hypotheses offered are discussed and evaluated in the
dialogue and the agents select the best proposal as the solution
to the conflict. All agents involved in the dialogue adapt the priority
ordering and adopt their plan to it. This means that there are many small local
changes to an agent's position in the global priority ordering and therefore also in
their plans. The end result is a global solution to the cooperative pathfinding
problem decentrally influenced by all agents. The conflict-resolving deliberation dialogues add explanatory power to the solution process.

We now provide a formal description of the cooperative pathfinding problem 
(\autoref{sec:problem}). Our family 
of algorithms combining ideas from these three fields is proposed in 
\autoref{sec:method}. This is followed by an evaluation and comparison to other 
algorithms in \autoref{sec:results}. The results are discussed in 
\autoref{sec:discussion}.
