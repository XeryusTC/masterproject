\section{Algorithm}\label{sec:method}
Decoupled algorithms are able to solve cooperative pathfinding problems while
requiring only minimal resources. The agents calculate paths to their
destination individually so this is inherently distributed. To achieve this
there has to be a predetermined priority order for the agents so that they can
plan paths that have no conflicts. This is often done by a central processor
that knows the optimal paths of all agents. This central processor can then
find dependencies between agents to determine possible priority orderings that
can be used to solve the problem \cite{latombe1991,bennewitz2002}. This means
that decoupled methods are mostly distributed with a single centralized
bottleneck. All agents will have to halt calculating a solution while the
priority scheme is determined by the central processor. The central processor
in its turn has to wait for all agents to calculate and communicate their
optimal paths before it is able to determine the priority order.

To overcome this bottleneck the calculation of the priority ordering can also
become distributed. The three step base decoupled method can be
altered to allow for this. The first step where each agent plans its optimal
path without regard for the other agents remains the same. Next agents share
the paths that they found with each other. Each agent can now determine where
its path and the paths of other agents
have conflicting moves that would lead to a collision. The agents will then be
able to solve the conflicts without having to wait for slower agents to
calculate and communicate their optimal paths. To solve conflicts agents will
start a dialogue where possible solutions are proposed, evaluated and adapted.
The proposals made consist of a priority order for the agents involved in the
conflict. Agents will only need to solve the first conflict that occurs in
their path because solving it may have the side-effect of solving later
conflicts. After a conflict has been successfully solved then the agents
involved can work on solving the next conflict.
Below are the details of three different versions of this algorithm, each
version of the algorithm has some improvements over the previous version.

Each of the three algorithms builds upon a more general search algorithm
Cooperative A* (CA*). This algorithm is a variation on A* \cite{hart1968} that
allows teams of agents to cooperate. Each agent searches for a path
individually, but they can take each other's actions into account. The
algorithm searches both the space and time dimensions to ensure that paths are
conflict free. To be able to do this an agent needs to know the paths of the
other agents that can potentially conflict with its own path. The algorithm
works like regular A* with the addition that it has to consider the moves that
other agents make. It does this by not expand nodes that would cause a conflict
with the path of an agent of higher priority. This results in a path which
leads the agent to its destination and it does not collide with other agents
during the execution of this plan. Because CA* is based on A* it will find the
shortest path which does so.

\subsection{Partial Cooperative A*}
The heart of the algorithm is the conflict resolution step. The most
straightforward approach to solving conflicts is by going through all possible
agent orderings. An ordering determines which agent has priority over another
agent. The ordering $a_1 > a_2$ indicates that $a_1$ can plan freely while
$a_2$ has to consider $a_1$ as a moving obstacle. Usually decoupled methods use
a permutation of the priority ordering $a_1 > a_2 > \ldots > a_k$ that all
agents have to adhere to. In Partial Cooperative A* (PCA*) start by finding
their optimal paths without considering the presence of the other agents and
communicating the results with each other. When agents detect that there is a
conflict in their individual plans then they will try to find a priority
ordering between them that will solve the conflict. Agents will always try to
find a solution to the conflict that is closest to their current position
first. This is because the solution to earlier occurring conflicts may also
have the effect of solving or creating later conflicts. There is no need to
waste computational resources on solving a conflict that will be solved by
implication when an earlier occurring conflict is solved.

To find the most suitable priority ordering scheme all possible orderings
between the agents that are involved in the conflict are evaluated. So a
conflict with two agents will result in the ordering $a_1 > a_2$ and $a_2 >
a_1$. The agents temporarily adapt the first ordering and plan new paths with
the constraints it introduces and the agents measure the length of the paths
that they found. Next they will adapt the second ordering and create a new plan
using its constraints and they also measure the length of their path with this
ordering. The priority scheme for which the sum of the path lengths is the
lowest is permanently adapted by the agents. Because the solution with the
lowest sum path length is used there is no consideration for the effects that
the solution has on conflicts that occur later.

Only the agents that occur in a priority ordering adapt it. This means that an
agent $a_3$ does not know about the ordering that agents $a_1$ and $a_2$ have
settled on, say that they picked $a_2 > a_1$. When $a_3$ and $a_1$ have a
conflict then this will also find a solution to it. If they settle on a
solution $a_1 > a_3$ then only $a_1$ knows $a_2 > a_1 > a_3$, the other two
agents only know the partial priorities. In this case the global priority is
known by $a_1$. It will not always be the case that one agent knows the
full priority ordering. The ordering is implied by the partial orderings that
the agents do know about. This is similar to how plans are constructed in
partial global planning where no agent knows what the global plan is either.
% TODO: incremental plans

The orderings that are found do not need to be unambiguous, if $a_1$ and $a_3$
had used the solution $a_3 > a_1$ then $a_1$ would have orderings $a_2 > a_1$
and $a_3 > a_1$ but no $a_2 > a_3$ or $a_3 > a_2$. This leaves $a_2$ and $a_3$
free to use any priority scheme in the event that they also have a conflict in
their paths. This also allows for circular priority orderings, something which
conventional decoupled algorithms do not support. This is possible because the
circular ordering is implicit in all the partial orderings that individual
agents know about. The implied global priority also doesn't need to be
complete, not every agent needs to be present in it. This is easiest to see
when considering only agents $a_1$ and $a_5$ in \autoref{fig:world}, for this
example the other agents do not exist. There is no need to establish an
ordering for these two agents since their paths never meet. This has the effect
of implied Independence Detection \cite{standley2010} because these agents will
never have to communicate beyond sharing the paths that they have found with
each other. There is no need for them to coordinate because their plans never
interact.
% Simplicity of algorithm b/c not able to predict consequences
% priorities form PGP

%The simplest approach to resolving the conflicts is by creating all possible
%ordering permutations for the agents involved in the conflict. The permutation
%that has the lowest sum path length is used as the solution for the conflict.
%This simple method of evaluating the various solutions is unlikely to find the
%most appropriate one because it is not able to predict the consequences of
%selecting one solution over the others.
%Most conflicts involve just two agents, so there are only two possible ordering
%permutations which means that the amount of priority permutations that need to
%be evaluated is low.

\subsection{Dialogue-based Partial Cooperative A*}
\begin{table}
    \centering
    \caption{Stages of a conflict resolution dialogue.}
    \label{tbl:stages}
    \begin{tabular}{l|l|l}
        Stage & Goal & Next stage \\ \hline
        Opening & Exchange information & Proposal \\
        Proposal & Make (incomplete) priority proposals & Evaluation \\
        Evaluation & Vote on suitability of proposals & Proposal, Closing \\
        Closing & Permanently adapt best proposal & \\
    \end{tabular}
\end{table}

Going through all possible permutations and evaluating them on a single
criterion is not the most clever method of finding a priority ordering
\cite{bennewitz2002}. This would mean that the entire search space is
exhaustively examined until a working solution is found. To avoid evaluating
all possible permutations and thereby reducing the time required to find a
solution some improvements can be made. Utilising a dialogue to solve conflicts
can reduce the number of priority combinations that need to be evaluated.
Agents take part in a dialogue of which the goal is to find a solution to the
conflict that works for all agents involved in the conflict. This dialogue
consists of several stages which are summarised in \autoref{tbl:stages}. For
each conflict the agents start a new dialogue. The agents work through the
conflicts in chronological order, they solve conflicts that occur early before
solving conflicts that occur later. The opening stage is where each dialogue
starts, during this stage the agents notify each other if they are taking part
in any dialogues for conflicts that occur earlier than the current conflict
being discussed. If there is such a prior dialogue then the current dialogue
will be put on hold all earlier dialogues are completed. If the conflict that
the dialogue is on is the earliest conflict for all involved agents then the
dialogue moves on to the proposal stage.

During the proposal stage each agent can enter a new ordering proposal that is
to be evaluated. Agents can make only one single proposal during each proposal
stage. There can be multiple of these stages during a dialogue so it is
possible for agents to make multiple proposals before the dialogue has
concluded. The proposed priority can be
partial, if there are three or more agents taking part of the dialogue then
$a_1 > a_2 > a_3$ is a valid proposal but $a_1 > a_2, a_3$ is as well. In the
latter case $a_1$ has priority over both $a_2$ and $a_3$, but there is no
established priority ordering between $a_2$ and $a_3$ yet and this may be
decided upon later during the dialogue, or during a future dialogue. Agents
will always propose that they get a higher priority over the other agents that
are part of the conflict. So in a dialogue that involves two agents $a_4$ and
$a_5$ each agent gets to make a proposal, $a_4$ will propose $a_4 > a_5$ while
$a_5$ will propose $a_5 > a_4$.

The third stage is the evaluation stage which is reached when all agents have
made a proposal or declined to make one. Each of the new proposals will be
evaluated in turn. To evaluate a proposed priority ordering the agents adapt it
and update their plans. During this replanning agents have to take into account
the constraints imposed by both the ordering in the proposal, and the ordering
imposed by previously solved conflicts. Once an agent has updated its plan then
it will cast a vote based on how suitable the proposal is. When an agent finds
that it is unable to plan a path to its destination under a certain proposal
then it will notify the other agents of this. In this case the proposal is
rejected by all agents and not voted on, it can also not be expanded on during
an extra proposal stage. If it is not the case that an agent is blocked from
reaching its destination then all agents will vote on their preference for a
proposal. Each vote consists of a single real number that represents how
suitable the proposal is. This number is based on the increase of the length of
the path, and whether the new plan solves or causes more conflicts at later
time steps. Both of these factors are weighted to result in the final vote. All
agents cast a vote on each acceptable proposal. The proposal with the highest
sum of the votes is accepted as the solution to the conflict. The votes of each
agents are weighted equally, so there is no agent which has a stronger vote.

After all the proposals have been evaluated there is room for agents to claim
to want to make additional proposals. If an agent does so then the dialogue
goes through another proposal and evaluation stage. If no agent wants to make
additional proposals the dialogue can be completed in the closing stage. During
the closing stage each agent will permanently adapt the priority scheme with
the highest sum of votes. The priority ordering in this proposal is always
considered when making new proposals and plans during future dialogues. This
completes the dialogue, the agents can now work on conflicts that still occur.
The entire above process is repeated for all conflicts until they are all
solved.

In conflicts that involve three or more agents it is not always the case that a
priority ordering will solve the conflict for all agents. In some conflicts
involving agents $a_1, a_2, a_3$ it may be the case that a partial ordering
$a_1 > a_2, a_3$ means that $a_1$ will not have a conflict with $a_2$ and $a_3$
any more, but that $a_2$ and $a_3$ will still have a conflict at another
position and/or time. In this case either agent can make a request for an
additional proposal round. During this proposal round the agents can make new
proposals or expand on additional proposals. Agents do not need to make
proposals so $a_1$ might not make any new proposals because it already has the
highest priority in the proposal $a_1 > a_2, a_3$. On the other hand $a_2$ and
$a_3$ are likely to make proposals, they could make the proposals $a_1 > a_2 >
a_3$ and $a_1 > a_3 > a_2$ respectively. After all three agents have entered a
proposal or declined to make one the dialogue moves to the evaluation stage
again. This time only the new proposals are evaluated.
% should not accept expanded proposals

Conflicts that involve more than two agents can be solved in two different
ways. The first is to let agents solve the conflict in pairs, this approach is
known as Dialogue-based Partial Cooperative A* (DPCA*). In a conflict between
the agents $a_1$, $a_2$ and $a_3$ at time $t$ then there would be three
dialogues: one between $a_1$ and $a_2$, one between $a_1$ and $a_3$, and one
between $a_2$ and$a_3$. Say that $a_1$ and $a_2$ are the first to hold a
dialogue which finishes with the priority $a_1 > a_2$, meaning that $a_1$ has
priority over $a_2$. Agent $a_2$ will have found a path that does not go
through the location of the conflict at $t$. This has the effect of also
solving the conflict between $a_2$ and $a_3$. Now only $a_1$ and $a_3$ still
have a conflict at $t$ and they will have to hold a dialogue about which agent
gets priority over the other. When this dialogue would end with the priority
scheme $a_1 > a_3$ then the multi-agent conflict at $t$ is solved. It may be
the case that $a_2$ and $a_3$ now have another conflict at a different position
and/or time that they will have to resolve. For this conflict there will be at
least two dialogues that need to lead to a conclusion, and at most three
conflicts if $a_2$ and $a_3$ do have a conflict at a different location.

The other approach is to have a single dialogue in which all agents
participate, this is known as Dialogue-based Partial Cooperative A* Plus
(DPCA*+). Having multiple agents in a dialogue will require that the dialogue
supports partial priority orderings and that it allows for multiple rounds of
making proposals and evaluating them. DPCA* does not need to have this
complexity in dialogues. DPCA*+ may be more complex than DPCA*, but it also
requires fewer dialogues to find a set of conflict free paths and therefore it
may be faster than DPCA*.

Each time that agents evaluate a proposal they have to compute paths that
satisfy the constraints imposed by the priority orderings. This often means
that agents have to recompute the same paths when their priority doesn't change
between proposals. Te reduce the amount of computation required agents can
store the paths that they have calculated. When agents need to calculate a path
to evaluate a proposal they can consult their path cache. This allows them to
use a path that has been found earlier and use that as a solution. The only
restriction is that the cached path does not have a conflict with the paths of
agents that have a higher priority. Some cached paths may cause new additional
conflicts with lower priority agents. This should not stop agents from using
this path because they can solve these conflicts in a later dialogue. Using a
cache should reduce the overall amount of time that is required to find a
conflict free set of paths for all agents.

\begin{figure}
    \centering
    \begin{subfigure}[t]{.3\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/dialogue-example-initial.pdf_tex}
        \caption{Initial configuration.}
        \label{fig:example-initial}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{.3\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/dialogue-example-prop1.pdf_tex}
        \caption{Configuration after proposal $a_2 > a_1$.}
        \label{fig:example-prop1}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{.3\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/dialogue-example-solution.pdf_tex}
        \caption{Configuration after proposal $a_1 > a_2$.}
        \label{fig:example-solution}
    \end{subfigure}
    \caption{Three stages of resolving a conflict. Agents are circles inscribed
    by $a_i$, their respective goals are $g_i$. Paths that are followed are
    indicated by the arrows. The red dot represent where two paths have
    conflicting moves.}
    \label{fig:example}
\end{figure}

\paragraph{Example of conflict resolution} Consider the cooperative pathfinding
problem in \autoref{fig:example-initial}. It shows a $4 \times 4$ grid with
three agents in it in their starting positions. The initial optimal paths they
found during the first step of the algorithm are shown as arrows.
Agent $a_1$ has a path that consists of three \emph{south} moves, $p_{a_{1},1}
= \{\text{\emph{south, south, south}}\}$, while both $a_2$ and $a_3$ have paths
that consist of three consecutive \emph{east} moves, $p_{a_2,1} = p_{a_3,1} =
\{\text{\emph{east, east, east}}\}$. None of the agents has a \emph{wait}
action in their path. After finding the initial paths all three agents share
their paths with each other, agents $a_1$ and $a_2$ discover that they collide
after their first action. This means that they will have to resolve this
conflict to prevent the collision.

Before discussing the details of how the agents resolve the conflict in this
situation some definitions are needed. A proposal where agent $a_i$ has
priority over a agent $a_j$ is represented as $a_i > a_j$. Agents can cast
votes on proposals, $\vote_{a_n}(a_i > a_j)$ is the vote of $a_n$ on the
proposal $a_i > a_j$. To be able to cast votes agents need to evaluate a
proposal. An evaluation  is based on two effects which can be weighted
differently. The first effect is the difference in path length before and after
a proposal has been adopted. The second effect is the change in the number of
conflicts that an agent is involved in, this effect is weighted three times
heavier than the former effect. Qualitatively this means that $\vote_{a_n}(a_i
> a_j) = 1 \cdot \Delta l + 3 \cdot \Delta c$ where $\Delta l$ is the
difference in path lengths and $\Delta c$ is the difference in conflicts.
Agents only communicate their final vote and not how they arrived at it.

Continuing with the example, after the agents have determined that they have a
conflict they start a new dialogue. The dialogue starts in its initial stage,
the opening. All messages are broadcast to all agents in the conflict dialogue,
in this case $a_1$ and $a_2$:
\\ \-\qquad $a_1$: no earlier conflicts
\\ \-\qquad $a_2$: no earlier conflicts

Because both agents don't have any conflicts that occur at an earlier time
(this is the first time step) the dialogue can move on to the proposal stage.
Both agents make a proposal in which they go first:
\\ \-\qquad $a_2$: propose $a_2 > a_1$
\\ \-\qquad $a_1$: propose $a_1 > a_2$

Both agents have made a proposal to resolve the conflict. The dialogue can
move to the evaluation stage. Agent $a_2$'s proposal will be evaluated first
because $a_2$ submitted the proposal before $a_1$. In this proposal agent $a_2$
has the highest priority so it doesn't need to update its plan and its path
remains $p_{a_2,1}$. It updates $a_1$ of the fact that its path hasn't changed
and still consists of three consecutive \emph{east} actions:
\\ \-\qquad $a_2$: new path $p_{a_2,1} = \{\text{\emph{east, east, east}}\}$

Agent $a_1$ does have to yield to $a_2$ so it will have to consider possible
conflicts that arise with $p_{a_2,1}$ and plan around them. It finds a new path
$p_{a_1,2} = \{\text{\emph{south east, south, south west}}\}$ which is shown in
\autoref{fig:example-prop1}. After finding the new path $a_1$ will evaluate its
quality so that it can send its vote to $a_2$. Before adopting the proposal the
agent had one conflict, this has not changed after making a new plan so $\Delta
c = 0$. There is no difference in the length of the paths before and after
temporarily adopting the constraints of the proposal, so $\Delta l = $. This
means that agent $a_1$ can send the vote to $a_2$. It will also send its new
path along with the proposal
\\ \-\qquad $a_1$: new path $p_{a_1,2} = \{\text{\emph{south east, south,
south west}}\}$
\\ \-\qquad $a_1$: $\vote_{a_1}(a_2 > a_1) = 0$

Now that $a_2$ knows the new path of agent $a_1$ after adopting to $a_2 > a_1$
it can also vote on the proposal. This happens in a similar vain as $a_1$'s
evaluation, there is however one fewer conflict for $a_1$ as its path doesn't
conflict with that of $a_2$ any more. Achieving this was the goal of the
dialogue. The path remained the same so $\Delta l = 0$ and $\Delta c = -1$, the
vote of $a_2$ is then $\vote_{a_2} = 1 \cdot \Delta l + 3 \cdot \Delta c = -3$.
This vote is then cast:
\\ \-\qquad $a_2$: $\vote_{a_2}(a_2 > a_1) = -3$

Now that this proposal has been evaluated by both agents they can find the sum
score of the proposal which is $\eval(a_2 > a_1) = \eval(a_1, a_2 > a_1) +
\eval(a_2, a_2 > a_1) =
-3$. Next the agents can evaluate $a_1 > a_2$. When agent $a_1$ goes to
evaluate this conflict if finds that it can use the path $p_{a_1,1}$ which is
stored in its cache. It can use this because it has a priority scheme similar
to the one being evaluated; $a_1$ does not have to yield to any agent. It
notifies $a_2$ of this:
\\ \-\quad $a_1$: new path $p_{a_1,1} = \{\text{\emph{south, south, south}}\}$

Next $a_2$ can evaluate the proposal. First it needs to plan a new path that
does not conflict with the path that $a_1$ has just send. It finds the path
$p_{a_2,2} = \{\text{\emph{north easth, east, south east}}\}$. The new
situation is shown in \autoref{fig:example-solution}. It can
immediately evaluate it, the lengths of $p_{a_2,1}$ and $p_{a_2,2}$ are equal
and $a_1$ has one fewer conflicts so $\Delta c = -1$.
\\ \-\quad $a_2$: new path $p_{a_2,2} = \{\text{\emph{north easth, east, south
east}}\}$
\\ \-\quad $a_2$: $\eval(a_2, a_1 > a_2) = 1 \cdot (|p_{a_2,2}| - |p_{a_2,1}|)
+ 3 \cdot \Delta c = -3$

Agent $a_1$ can also send its evaluation to $a_2$:
\\ \-\quad $a_1$: $\eval(a_1, a_1 > a_2) = 1 \cdot (|p_{a_1,1}| - |p_{a_1,1}|)
+ 3 \cdot \Delta c = -3$

Now both agents have evaluated the proposal $a_1 > a_2$ they can find the sum
of the evaluations which is $\eval(a_1 > a_2) = \eval(a_1, a_1 > a_2) +
\eval(a_2, a_1 > a_2) =
-6$. All proposals have been evaluated so the agents can notify each other if
they want to make more proposals:
\\ \- \quad $a_1$: no more proposals
\\ \- \quad $a_2$: no more proposals

Neither agent wants to make more priority ordering proposals, this is because
there are no more possible priority orderings to make with these two agents.
The dialogue can then move to the closing stage. In the closing stage agents
will pick the best proposal, in this case that is the proposal with the lowest
sum score which is the proposal $a_1 > a_2$. To adapt this proposal agents will
need to use the respective paths that they used during the evaluation of the
proposal. So $a_1$'s path will be $p_{a_1,1}$ while $a_2$'s path will be
$p_{a_2,2}$. They also need to keep track of which agents have a higher
priority than themselves. For agent $a_1$ nothing changes, while $a_2$ must now
store that $a_1$ has a higher priority than it. All conflicts in
\autoref{fig:example} have now been solved and agents are free to execute their
paths.

To evaluate a proposal an agent needs to weigh different factors of the
quality. In this example a weight of 1 for the path length and a weight of 3
for the number of solved/introduced conflicts was used. These weights are used
for demonstration only and an implementation should have these weights set
empirically. The weights can be any real number. When dialogues between groups
of three or more agents are possible then a third penalty weight can be added.
This penalty weight is included in the evaluation if there are two or more
agents that still have a conflict with each other after adapting a priority
proposal. It is a penalty for when a proposal only partially solves a conflict.

\subsection{Windowed Dialogue-based Partial Cooperative A*}
One of the issues with DPCA* and DPCA*+ is that all dialogues and computation
occur before execution of the plan. Both planning and execution take time
without requiring the same resources so it is also possible to do them at the
same time. This means that the plan can be executed while it is still being
constructed. One way of doing this is by applying a window to restrict how far
away from an agent's location DPCA* will be used to solve conflicts. A
window $w$ determines that agents will use the above algorithm to solve all
conflicts that occur within $w$ time steps from their current position. Agents
will not cooperate past the boundary of the window, solving conflicts that
happen beyond that border is deferred to a later point in time. Periodically
the agents will move their window and solve any new conflicts in the window.
Because agents only coordinate in the window it is not necessary for them to
plan a path past the window boundary as well. Instead agents can plan a path
for the next $w$ time steps so they get closer to their goal. To achieve this
the graph can be changed so that the nodes at the window boundary connect
directly to the goal node. This can be achieved by changing the cost function
defined in \autoref{sec:problem} between adjacent nodes $P$ and $Q$
\cite{silver2005}
\[
\text{\textsc{cost}(P,Q)} =
\begin{cases}
    0 & \text{if } P = Q = G, t < w \\
    \textsc{HeuristicDistance(P,G)} & \text{if } t = w \\
    1 & \text{otherwise}
\end{cases}
\]
where \textsc{HeuristicDistance} is a function that returns the cost of the
shortest path between $P$ and $G$ if there are no other agents on the graph.

Using the window spreads out the computation over the course of execution, but
it has other benefits as well. Exchanging optimal paths between agents after
the first step may take a long time in large multi-agent systems.
By limiting the search using a window agents only need to coordinate with a
limited number of other agents. This reduces
the initial planning time, as well as for each subsequent window. Agents that
are never in each other's window will never have to communicate with each other,
saving a lot of unnecessary communication and conflict detection overhead.
Windowing the search also has benefits in systems where agents can change their
destination during execution. Instead of recalculating the entire plan when
this happens, only agents within the window of the agent changing destination
have to update their plan. Agents that are not affected by the change in
destination do not have to update their plan. When there would be no window all
agents would have to recalculate and solve all conflicts again, even if they
would not need to update their plan, leading to wasted computational resources.

An overview of all proposed algorithms is given in \autoref{tbl:proposed}, the
categories shown are similar to those in \autoref{tbl:planning-overview}. Some
of the columns from \autoref{tbl:planning-overview} are missing in
\autoref{tbl:proposed} because these have the same values for all proposed
algorithms. Each algorithm is decentralized because they do not rely on a
central processor at any time. The algorithms are heavily influenced by the
three step decoupled approach where agents first calculate optimal routes, then
find a priority ordering and finally plan a route to their destination that
adhere to the constraints that are imposed by the priority ordering. None of
the methods is complete because they belong to categories that generally do not
include complete algorithms. The meaning of the communication column in
\autoref{tbl:proposed} is more specific of that in
\autoref{tbl:planning-overview}; here it means in which range agents can start
dialogues with each other. The meaning of the online column remains the same,
an offline algorithm completes planning before execution while an online
algorithm interleaves making and executing plans. There ``valuations'' column
is new, it indicates whether agents are allowed to evaluate proposals and share
the evaluations with each other.

\begin{table}
    \centering
    \caption{Comparison of proposed cooperative pathfinding algorithms. The
    communication and online columns are similar to that in
    \autoref{tbl:planning-overview}.}
    \label{tbl:proposed}
    \begin{tabular}{l|l|l|l}
        Algorithm & Communication & Online & Valuations \\ \hline
        PCA*   & All & No & No \\
        DPCA*  & All & No & Yes \\
        WDPCA* & Window & Yes & Yes \\
    \end{tabular}
\end{table}