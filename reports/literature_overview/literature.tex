\documentclass[a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage[all]{hypcap}

\title{Literature summary}
\author{Xeryus Stokkel}

\begin{document}

\maketitle

\section{Related work}
\subsection{Cooperative pathfinding}
Cooperative pathfinding is the field of study that aims to find methods of
finding conflict free paths for groups of agents. Given a connected grid and a
group of $k$ agents with initial positions $s_1, \ldots, s_k$ and goal
positions $g_1, \ldots, g_k$, a set of paths is conflict free iff all agents
$a$ have a path from $s_a$ to $g_a$ without any two agents ever occupying
the same position at the same time, or moving along crossing edges at the same
time. Each agent can take one of $b+1$ actions, where $b$ is the current number
of nodes the agent can move into, there is also a \textit{wait} action where an
agent does not move. Agents are allowed to move at the same time and are
allowed to move to a position if the currently occupying agent also moves in
the current time step. The naive approach to this problem takes the Cartesian
product of all $k$ state spaces and searches the new combined state space with
an algorithm like A*. This results in a branching factor of $(b+1)^k$, the
branching factor grows exponentially in the number of agents and the problem
quickly becomes intractable even with efficient search algorithms like A*
\cite{sharon2013}.

There are a few categories that methods tackling this problem fall into.
Centralised methods use one single processor to calculate the paths for all
agents. They are often complete, they will find a solution to the problem if it
exists. This often also means that they are slow. Decoupled methods let each
agent plan its own path and enforces a hierarchy on the agents so that agents
lower in the hierarchy need to give way to agents higher in the priority.
Decoupled methods sacrifice completeness for speed. They often calculate the
priorities at a central processor, but can exploit the parallelism in
multi-agent systems to calculate the paths. There are also reactive methods
that will only solve conflicts when they occur during plan execution.
\autoref{tbl:planning-overview} shows an overview of several algorithms and
summarises their properties, each algorithm is discussed in more detail below.

\begin{table}[h]
	\centering
	\caption{Comparison of cooperative pathfinding algorithms. Communication
	indicates what limit is imposed on which agents can communicate, `all'
	means that there is no limit and agents can communicate with all others.
	Planning enumerates whether all movement actions for all agents are
	determined before execution, some algorithms update the plan during
	execution.}
	\label{tbl:planning-overview}
	\begin{tabular}{l|l|l|l|l|l}
		Method & Category & Complete & Priority & Communication & Planning \\
		\hline
		WHCA* & Decoupled & No & Yes\footnotemark[1] & Window & During \\
		OD+ID & Centralised & Yes & No & All & Before \\
		ICTS & Centralised & Yes & No & All & Before \\
		DMRCP & Decentralized & No & No & 2 node radius &
		During \\
		ADPP & Decoupled & No & Yes & All & Before \\
		%Proposed & Decentralized & No & Partial & All & Before
	\end{tabular}
\end{table}
\footnotetext[1]{Although WHCA* does give agents a priority, the assigned
priorities can vary between windows.}

One centralized method called Operator Decomposition (OD) deals with the
intractability of
the problem is by considering the possible moves of each agent on their own
\cite{standley2010,standley2011}. Instead of taking the Cartesian product of
the agents' state spaces it assigns actions to agents individually. This leads
to two different kind of states: in standard states no agent has been assigned
an action; in intermediate states some of the agents have been assigned an
action, when all agents are assigned an action it results in a new standard
state. Because intermediate states are considered individually the algorithm is
less likely to expand those intermediate states that are sub-optimal and thus
fewer states are generated. The result of this is that the branching factor
becomes $(b+1)$, but that the depth of the solution in the search tree grows
with a linear factor $k$. This makes finding a solution with an algorithm like
A* more tractable. OD is a complete and optimal algorithm, meaning that it will
always find a solution if one exists, and it will find the best solution.

On its own OD is not always very efficient, so an additional algorithm called
Independence Detection (ID) was introduced \cite{standley2010}. Before planning
takes place all agents are placed in their own group. Each group then makes a
plan, when the paths for two groups conflict then one group is tasked with
finding a new conflict free path. If this also fails then the groups are merged
and a new plan is formed for the group using OD. This is repeated until a
set of conflict free paths for all agents has been found. Several variants on
ID+OD have been proposed, leading to the Optimal Anytime algorithm
\cite{standley2011} which will quickly find a solution and can then spend more
time on improving the solution. Because ID is an extension that can be applied
to any cooperative pathfinding algorithm OD+ID is still complete. Although
there is implicit priority in the order of agents that is planned for, it has
no influence on the ability to find a solution or the quality of the solution.
Planning is completed before agents start executing it, and there is no need to
update the plan during execution.

Another centralized method is called the Increasing Cost Tree Search (ICTS)
which is a
two-fold search method \cite{sharon2013}. It consists of a high-level search on
an Increasing Cost Tree (ICT) which has a root node which contains the optimal
path costs for each individual agent. Each child node increases the path cost
for a different agent, so each level in the tree increases the sum of the path
costs by one. This tree is searched using breadth-first search, each node in
the tree will be searched using a low-level search. This low level search
generates all paths for each agents that is equal to the cost in the current
ICT node, it will then try to find a conflict free combination of these paths.
If such a set of paths exists then the algorithm is done, otherwise the
high-level search will continue to the next node in the ICT. Pruning can be
used to decrease the amount of duplicate nodes in the ICT, but it is possible
to use ID as well. The ICTS is a complete algorithm like OD+ID, but it is
faster in situations when the number of agents relative to the number of nodes
is high. ICTS imposes no priority on the agents at all since it only searches
for combination of paths that are a valid solution to the problem. Finding
conflict free paths that agents have to take happens before agents start moving.

The above algorithms all fall into the centralized category of solutions, these
can become very slow because of the state-space explosion. Decoupled methods
reduce the required calculation time by considering each agent separately. They
generally use the same three step approach;
\begin{enumerate}
	\item Find optimal paths for each agent independently of each other.
	\item Impose a hierarchy on the agents, often this is done by assigning
	them a unique priority.
	\item Make new plans for all the agents, this time an agent has to consider
	all agents with a higher priority as a moving obstacle. Agents with a lower
	priority can safely be ignored.
\end{enumerate}
This leads to a set of conflict free plans. Finding the optimal priority order
is a combinatorial problem
\cite{bennewitz2002}. A common algorithm of assigning priorities first
calculates a dependence hierarchy based on the paths found in the first step,
then priorities can be assigned such that agents have a priority that is higher
than that of agents that may block them. Circular dependencies may mean that
multiple priority schemes may have to be tried. The quality of the final
solution depends highly on the priority ordering employed, some of the possible
priority schemes may not even lead to a solution. This means that these kind of
algorithms are not complete.

Most proposals for decoupled methods don't mention whether a central processor
must make the plans for all agents, or whether the agents can do it themselves.
Determining the prioritization scheme is often centralized, since a
single processor needs to determine all dependencies \cite{bennewitz2002}. One
method called Asynchronous Decentralized prioritized Planning \cite{cap2012}
exploits the inherent parallelism of a multi-robot team during the planning
stages. The method allows
agents to make their individual plans, after an agent has found a path it will
notify all agents with a lower priority of its (new) path. These lower priority
agents will then update their plans if conflicts arise, notifying lower
priority agents. These agents will then update their plans etc. The benefit of
this method is that agents can make a new plan as soon as any one higher
priority agent has send a conflicting plan, there is no need for agents to
wait for each other to finish their plans. This means that agents can plan
simultaneously and that some agents may finish planning before higher priority
agents if their paths are conflict free.

Windowed Hierarchical Cooperative A* (WHCA*) is a decoupled algorithm that has
been very successful in the video-game industry \cite{silver2005}. It uses a
reservation table to denote where agents plan to be and thus prevent agents
from entering the same space at the same time. It requires that agents have
been assigned a priority ordering in which they plan so that they can take each
other's reservations into account. The amount of computation required depends
on the quality of the heuristic used during A* planning. Hierarchical A* is an
abstraction of the search space used to obtain perfect distance estimates. The
reservation table and time dimension are ignored for this so that agents can
find the minimum distance to their destination. The search by the above
algorithm is windowed so that the reservation table is only used in the window
and the rest of the path is planned in the abstract space, ignoring the other
agent's actions. The window is moved at regular intervals and the agent's plan
is updated. Because of this the agents have no fixed priority, it varies based
on the current window. Computation is spread out over the time it takes for
agents to get to their destination, so there is no need to calculate all paths
before execution, they are instead updated during execution. Another issue that
is solved is that agents would reach their goal position and stay there,
potentially blocking the paths of other agents. The window limits the size of
the reservation table the agents have to take into account, limiting the
communication between agents to the size of the window.

One model of truly decentralized cooperative pathfinding called DMRCP has been
proposed by
\cite{wei2016}. Agents move towards their destination and only communicate with
each other in a two graph node radius. They can give each other commands like
move out of the way, follow me, wait etc. Agents are altruistic which means
that they are willing to make concessions during conflicts even if that means
that they will be at a disadvantage. Agents use various strategies to deal with
different conflict situations. Because of the limited communication range and
the various strategies employed the agents often need to recalculate the
optimal path to their destination during the execution of their old plan. This
approach works well, it requires slightly less computation time than OD+ID and
on average the agents only need two thirds of the number of movement steps to
reach their goal positions. Although completeness is not discussed, the
algorithm is based in decoupled methods which are generally not complete. Some
of the strategies that agents use to resolve conflicting situations are aimed
at resolving deadlocks.

\subsection{Argumentation}
Argumentation has long been studied by philosophers, but it has been used in
the field of Artificial Intelligence as well. In AI it has mainly been studied
in the fields of
legal argumentation (AI \& Law), defeasible reasoning and multi-agent systems.
One of the main pillars is non-monotonic logic. A logic is non-monotonic when a
conclusion that follows based on the premises does not necessarily hold any
more when additional premises are added \cite{vaneemeren2014}. A classic
example of this is that birds can fly, so when you see a bird you assume that
it can fly. However, when you're told that the bird is a penguin and that
penguins can't fly then you will no longer conclude that the bird can fly. An
argument is defeasible when it can be defeated by other arguments, in the
previous example the fact that the bird that you see can fly is defeasible.

Pollock distinguishes two different types of defeating arguments
\cite{pollock1995}. \emph{Rebutting defeaters} attack an argument directly and
give a reason for an opposite argument. \emph{Undercutting defeaters} do not
attack an argument directly, instead they attack the relation between an
argument and its support. The standard example given by Pollock is about an
object that looks red: "The ball looks red to John" is a support for John to
believe that the ball is red, but there may be a red light shining on the ball.
This is a undercutting defeater because it does not attack the conclusion
directly, instead it attacks the relation between the observation and the
conclusion that the ball is red, after all, a white object with a red light
shining on it will also look red.

Other researchers have formulated additional forms of defeaters, but they can
be distilled into three main forms \cite{vaneemeren2014}:
\begin{description}
	\item[Undermining defeaters] attack the premises or assumptions of an
	argument.
	\item[Undercutting defeaters] attack the connection between a set of
	reasons and the conclusion in an argument.
	\item[Rebutting defeaters] raise an argument in favour of an opposite
	conclusion, thereby attacking an argument.
\end{description}

A formal model of argumentation that introduces a structure to ease the
computation of validity in arguments has been proposed in a highly influential
paper by Dung \cite{dung1995}. This work focused mainly on the argument attacks
as a formal relation, giving the model the name of abstract argumentation. The
main concept is the \emph{argumentation framework}, a directed graph in which
the nodes form arguments and the edges between them represent one argument
attacking another. An important concept that Dung introduced was that of
admissibility of sets of arguments. A set of arguments is admissible when it is
conflict free and acceptable. A set being conflict free means that no argument
in the set attacks another argument in the set. Acceptability means that when
an argument is attacked by another argument outside of the set, then the set
attacks that argument. In other words the admissible set defends itself from
attacking arguments. On top of this Dung formulated other semantics. The
preferred extension is the set theoretically maximal admissible set, that is,
it is the largest possible admissible set such that adding one argument from
the argumentation framework would make it not admissible. There is also the
stable extension, this is an admissible set that attacks all arguments that are
not in the set.

One important notion of an argumentation framework is that of the grounded
extension. This extension is simple to compute by labelling the arguments in
the argumentation framework as `justified' or `defeated':
\begin{enumerate}
	\item All unlabelled arguments $\alpha$ in the framework can be labelled as
	`justified' if all arguments that attack $\alpha$ are labelled as
	`defeated'. Note that when $\alpha$ is not attacked that it can then also
	be labelled as `justified'.
	\item All unlabelled arguments $\alpha$ in the framework that are attacked
	by an argument that has been labelled `justified' is labelled as `defeated'.
	\item Steps 1 and 2 are repeated until all arguments have been labelled.
\end{enumerate}
A finite argumentation framework is labelled in a finite amount of steps. All
arguments that have been labelled as `justified' are included in the grounded
extension. All arguments that have been labelled `defeated' are not included in
the grounded extension.

\subsubsection{Dialogues}
Multiple agents can have an argument through a dialogue. Walton and
Krabbe \cite{walton1995} proposed a typology of main dialogues that humans
partake in. They distinguish six main types of dialogues, it should be noted
that the list of dialogue types is not exhaustive. In \emph{information
seeking} dialogues some of the participating agents aim to gather information
from another agent that knows the anser. In \emph{inquiry} dialogues a group of
agents collectively seeks an answer to a question to which non of the
participating agents knows the answer on its own. \emph{Deliberation} dialogues
are about what course of action to take in a given situation. A
\emph{persuasion} dialogue occurs when an agent tries to convince on or
multiple other agents of its position. It is successful when the other agent(s)
adopt its position. Participants of \emph{negotiation} dialogues try to find a
division of a scarce resource that all agents can be satisfied with. Finally
\emph{eristic} dialogues are a verbal substitute for fighting. Note that most
actual dialogues combine these dialogue types.

Dialogues are often analysed in a game-theoretic sense, where the utterances
that agents can make are analogous to the moves in a game. Which utterances are
appropriate at each moment is then defined by the rules of the game. Most of
the research into dialogues follows this approach
\cite{prakken2006,prakken2009}. Most dialogue systems have a two language
set-up. The first is the topic language which is about what agents are
discussing and is usually a logical language, it defines the context of the
dialogue. The second language is the communication language which specifies
which utterances can be made, what effects they have and the rules of outcome.
This latter language is at the core of dialogue games. Most dialogue systems
have the following syntax in common \cite{prakken2006,prakken2009,mcburney2009}.
\begin{description}
	\item[Commencement rules] Rules that concern when and how a dialogue can
	start and what its context is.
	\item[Locution rules] Which utterances are permitted are known as the
	locution rules. They may also define when an utterance is obligatory.
	Common locutions include asserting propositions, questioning or contesting
	assertions and justifying previous assertions after they have been
	questioned.
	\item[Commitments] Some locutions incur commitments on an agent which are
	subsequently put into the agent's commitment store. A dialogue system may
	limit which utterances an agent can make based on what is in its commitment
	store.
	\item[Speaker order] Most dialogue systems specify an order in which agents
	can speak, this can range from agents alternating turns to each agent being
	allowed to make an utterance at any time.
	\item[Outcome rules] These determine what the outcome of the dialogue is.
	Some systems define an outcome while the dialogue may continue and lead to
	a different outcome at a later point.
\end{description}

One model of deliberation dialogues is presented in \cite{mcburney2007}. It
consists of eight stages, starting with an \textbf{Open} stage and ending with
a \textbf{Close} stage. The other stages can occur multiple times during a
dialogue in any valid order. During the dialogue agents will collect the
preferences, goals and other constraints that need to be considered. Agents
will then propose common plans of action, when multiple plans have been
proposed agents can specify which they prefer. At some points an agent can
recommend a plan after which all agents will vote for that plan. The dialogue
requires unanimity before the recommended plan is adopted, but it allows for a
voting mechanism to pick the most preferred plan among many. Variants of this
model that require less stages that still achieve the same outcomes
\cite{dunin-keplicz2011}.

\subsection{Coordination}
Pollock \cite{pollock1995} introduces hierarchical plans. An agent starts out
by  making a global plan consisting only of coarse steps. This saves
computation time and it defers planning specific actions to a later time when
more information about the problem is available. When the agent reaches a step
in a plan that is not concrete enough yet it will start constructing a sub-plan
for that step, it may also do this when another planning process depends on it.
This is done in multiple levels leading to a hierarchical plan, the lowest
level consists of basic actions that are inherent in the agent (like lifting an
arm). At the same time the agent also keeps track of whether it is still
possible to execute the future steps in the plan. The agent will have to adapt
its plans once it notices that the remainder of the plan is not executable any
more for any reason. This allows an agent to adapt to a changing environment
and changing desires. Although this design focusses on planning actions for a
single agent it can easily be extended to planning for groups of agents.

Coordination in a multi-agent system can be done through partial global
planning \cite[pp. 202--204]{woodridge2009}, \cite{durfee1991}. The goal is to
let agents cooperate without any
one of them formulating a global plan, instead agents will coordinate with
other agents only when they need to. This leads to the construction of many
local plans, which can be communicated to other agents as well. This means that
eventually there will be a global plan that covers all agents, but the agents
themselves will only know a part of the global plan. Key to partial globabl
planning is that no agent needs to know the global plan, it only needs to know
which parts of the plan it is affected by. This approach is similar
to that of decoupled cooperative pathfinding because they use a similar
planning structure. Partial global planning starts out with letting each agent
make their individual goals, next agents communicate information on where plans
interact, finally they will alter their plans such that their actions are
better coordinated and there are no negative influences.

\bibliographystyle{plain}
\bibliography{biblio}

\end{document}
