\section{Family of algorithms}\label{sec:method}
Decoupled algorithms are able to solve cooperative pathfinding problems while
requiring only minimal computational resources. The agents calculate paths to
their destination individually so this is inherently distributed. A hierarchy
is imposed on the agents by assigning them a priority order. This order allows
agents to avoid conflicts without a central processor making a plan. However a
central processor is still needed to determine the priority order. This central
processor is used to
find dependencies between agents to determine possible priority orderings that
can be used to solve the problem \cite{latombe1991,bennewitz2002}. This means
that decoupled methods are mostly distributed with a single centralized
bottleneck. All agents will have to halt calculating a solution while the
priority scheme is determined by the central processor. The central processor
in its turn has to wait for all agents to calculate and communicate their
optimal paths before it is able to calculate the priority order.

To overcome this bottleneck the calculation of the priority ordering can also
become distributed. The decoupled method can be
altered to allow for this. The first step where each agent plans its optimal
path without regard for the other agents remains the same. Next agents share
the paths that they found with each other. Each agent can now determine where
its path and the paths of other agents have conflicting moves that would lead 
to a collision. The agents will then be able to solve the conflicts that occur 
without having to wait for slower agents to
calculate and communicate their optimal paths. To solve conflicts agents will
start a dialogue where possible solutions are proposed, evaluated and adapted.
The proposals made consist of a priority order for the agents involved in the
conflict. Agents will only need to solve the first conflict that occurs in
their path because solving it may have the side-effect of solving or causing 
later
conflicts. After a conflict has been successfully solved then the agents
involved can work on solving the next conflict.
Below are the details of three different versions of this algorithm. Each
version of the algorithm has some improvements over the previous version.

Three algorithms build upon a more general search algorithm
Cooperative A* (CA*). This algorithm is a variation on A* \cite{hart1968} that
allows teams of agents to cooperate. Each agent searches for a path
individually, but they can take each other's actions into account. The
algorithm searches both the space and time dimensions to ensure that paths are
conflict free. To be able to do this an agent needs to know the paths of the
other agents that can potentially conflict with its own path. The algorithm
works like regular A* with the addition that it has to consider the moves that
other agents make. It does this by not taking actions that would cause a
conflict
with the path of an agent of higher priority. This results in a path which
leads the agent to its destination and it does not collide with other agents
during the execution of this plan. Because CA* is based on A* it will find the
shortest path which does so.

\subsection{Partial Cooperative A* (PCA*)}

\begin{algorithm}[t]
    \caption{Partial Cooperative A*}
    \label{alg:pca}
    \begin{algorithmic}[1]
        \State $Permanent \gets \emptyset$
        \State $Path \gets \Call{FindPath}{Permanent}$
        \State $\Call{CommunicatePath}{Path}$
        \While{$\Call{HasConflict}$}
        \State $conflict \gets \Call{EarliestConflict}$
        \State $Orderings \gets \Call{PriorityOrderings}{conflict}$ 
        \State $Cost \gets \emptyset$
        \ForAll{$ordering \in Orderings$}
        \State $Path \gets \Call{FindPath}{Permanent \cup ordering}$
        \State $Cost[ordering] \gets \Call{PathCost}{path}$
        \EndFor
        \State $Permanent \gets Permanent \cup \{ \argmin_{ordering}{Cost} \}$
        \State $Path \gets \Call{FindPath}{Permanent}$
        \State $\Call{CommunicatePath}{Path}$
        \EndWhile
    \end{algorithmic}
\end{algorithm}

The heart of the algorithm is the conflict resolution step. The most
straightforward approach to solving conflicts is by going through all possible
agent orderings. An ordering determines which agent has priority over another
agent. The ordering $a_1 > a_2$ indicates that $a_1$ can plan freely while
$a_2$ has to consider $a_1$ as a moving obstacle. Usually decoupled methods use
a permutation of the priority ordering $a_1 > a_2 > \ldots > a_k$ that all
agents have to adhere to. Our algorithm Partial Cooperative A* (PCA*) does this 
for smaller groups of agents, it is outlined in \autoref{alg:pca}. Initially 
agents find their optimal paths without considering the presence of other 
agents (line~1 and line~2) and communicate the result with each other (line~3).
When agents detect that there is a conflict in their individual plans then they 
will try to find a priority ordering between them that will solve the conflict. 
Agent will always try to find a solution to the conflict that is closest to 
their current position first (line~5). This is because the solution to earlier 
occurring conflicts may have the side-effect of solving or creating later 
conflicts. There is no need to waste computational resources on solving a 
conflict that will be solved by implication when an earlier occurring conflict 
is solved.

To find the most suitable priority ordering scheme all possible orderings
between the agents that are involved in the conflict are evaluated (line~6--11 
in \autoref{alg:pca}). A conflict with two agents will result in the orderings 
$a_1 > a_2$ and $a_2 > a_1$ being evaluated. The agents temporarily adapt the 
first ordering and plan new paths with the constraints it introduces (line~9). 
The agents measure the length of the paths that they found (line~10). They do 
this for each priority ordering that is possible. The priority ordering with 
minimal increase in sum of path lengths is permanently adapted by the 
agents (line~12). A new path is calculated and communicated with all other 
agents (line~13 and line~14). Because the solution with the lowest sum path 
length is used there is no consideration for the effects that the solution has 
on conflicts that occur later.

Only the agents that occur in a priority ordering adapt it. This means that an
agent $a_3$ does not know about the ordering that agents $a_1$ and $a_2$ have
settled on, say that they picked $a_2 > a_1$. When $a_3$ and $a_1$ have a
conflict then PCA* will also have to find a solution for it. If they settle on 
the
solution $a_1 > a_3$ then only $a_1$ knows $a_2 > a_1 > a_3$, the other two
agents only know their partial priorities. In this case $a_1$ holds all 
information to obtain the global priority ordering. Often it is not the 
case that a single agent knows the
full global priority ordering. The global ordering is implied by the local 
partial orderings that the agents do know about. This is similar to how plans 
are constructed in partial global planning where no agent knows what the global 
plan is either.
% TODO: incremental plans

The orderings that are found do not need to be unambiguous, if $a_1$ and $a_3$
had used the solution $a_3 > a_1$ then $a_1$ would have orderings $a_2 > a_1$
and $a_3 > a_1$ but $a_2 > a_3$ or $a_3 > a_2$ is not known. This leaves $a_2$ 
and $a_3$
free to use any priority scheme in the event that they also have a conflict in
their paths. This also allows for circular priority orderings, something which
conventional decoupled algorithms do not support \cite{bennewitz2002}. This is 
possible because the
circular ordering is implicit in all the partial orderings that individual
agents know about. The implied global priority also doesn't need to be
complete: not every agent needs to be present in it. This is easiest to see
when considering only agents $a_1$ and $a_5$ in \autoref{fig:world}. For this
example the other agents are not relevant. There is no need to establish an
ordering for these two agents since their paths don't intersect. This has the 
effect
of implied Independence Detection \cite{standley2010} because these agents will
never have to communicate beyond sharing the paths that they have found with
each other. There is no need for them to coordinate because their plans never
interact.
% Simplicity of algorithm b/c not able to predict consequences
% priorities form PGP

%The simplest approach to resolving the conflicts is by creating all possible
%ordering permutations for the agents involved in the conflict. The permutation
%that has the lowest sum path length is used as the solution for the conflict.
%This simple method of evaluating the various solutions is unlikely to find the
%most appropriate one because it is not able to predict the consequences of
%selecting one solution over the others.
%Most conflicts involve just two agents, so there are only two possible ordering
%permutations which means that the amount of priority permutations that need to
%be evaluated is low.

\subsubsection{Example of conflict resolution}

Consider the configuration of agents shown in \autoref{fig:pca-initial}. It 
shows a $4 \times 4$ grid that contains the agents $a_1, a_2$, and $a_3$ with 
goal positions $g_1, g_2$, and $g_3$ respectively. The optimal paths to their 
destinations are shown as arrows. Agent $a_1$ has a path that consists of three 
\emph{south} moves, $p_{a_1,1} = \{\text{\emph{south, south, south}}\}$, while 
both $a_2$ and $a_3$ have paths that consist of three consecutive \emph{east} 
moves, $p_{a_2,1} = p_{a_3,1} = \{\text{\emph{east, east, east}}\}$. None of 
the agents has a \emph{wait} action in their path. After the agents have 
calculated and shared 
their optimal paths they find that $a_1$ and $a_2$ have a conflict after their 
first action. 

\begin{figure}
    \centering
    \begin{subfigure}[t]{.3\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/pca-example1.pdf_tex}
        \caption{Initial configuration showing $p_{a_1,1}$, $p_{a_2,1}$ and 
            $p_{a_3,1}$.}
        \label{fig:pca-initial}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{.3\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/pca-example2.pdf_tex}
        \caption{Configuration after priority ordering $a_1 > a_2$. Agent 2 now 
            has path $p_{a_2,2}$.}
        \label{fig:pca-2}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{.3\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/pca-example3.pdf_tex}
        \caption{Configuration after priority ordering $a_2 > a_1$. Agent 1 now 
            has path $p_{a_1,2}$.}
        \label{fig:pca-3}
    \end{subfigure}
    
    \begin{subfigure}[t]{.4\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/pca-example5.pdf_tex}
        \caption{Configuration after priority orderings $a_1 > a_2$ and $a_2 > 
            a_3$. Paths shown are $p_{a_1,1}, p_{a_2,2}, p_{a_3,2}$.}
        \label{fig:pca-4}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{.4\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/pca-example4.pdf_tex}
        \caption{Configuration after priority orderings $a_1 > a_2$ and $a_3 > 
            a_2$. Paths shown are $p_{a_1,1}, p_{a_2,3}, p_{a_3,1}$.}
        \label{fig:pca-5}
    \end{subfigure}
    
    \caption{Five stages of resolving a conflict using PCA*. Agents are circles
        inscribed by $a_i$, their respective goals are $g_i$. Paths that are 
        followed are indicated by the arrows. The circles indicate where agents 
        have conflicting moves in their paths.}
    \label{fig:pca-example}
\end{figure}

Before discussing the details of how the agents resolve the conflict in this
situation some definitions are needed. A proposal where agent $a_i$ has
priority over agent $a_j$ is represented as $a_i > a_j$. To resolve this 
conflict they evaluate the priority ordering proposals 
$a_1 > a_2$ and $a_2 > a_1$. The situation after adapting $a_1 > a_2$ is shown 
in \autoref{fig:pca-2}, it shows that $a_2$ has a new path $p_{a_2,2} = 
\{\text{\emph{south east, east, north east}}\}$. The situation after adapting 
$a_2 > a_1$ is shown in \autoref{fig:pca-3}, it shows that $a_1$ has a new path 
$p_{a_1,2} = \{\text{\emph{south east, south, south west}}\}$. Both of these 
paths have an equal length so neither of them is strictly better. In this 
example ties are broken in favour of the lower numbered agent, so the priority 
ordering $a_1 > a_2$ is permanently adopted by $a_1$ and $a_2$. Agent $a_3$ 
does not adapt the priority ordering.

The situation is now as shown in \autoref{fig:pca-2} where the paths 
$p_{a_2,2}$ 
and $p_{a_3,1}$ have two conflicts. Agent $a_1$ is not involved in these 
conflicts because it visits the first conflict location after $a_2$ and $a_3$ 
leave it. To resolve this conflict the agents evaluate the priority orderings 
$a_2 > a_3$ and $a_3 > a_2$. The situation after adopting $a_2 > a_3$ is shown 
in \autoref{fig:pca-4}, it shows that $a_2$ still has path $p_{a_1,2}$ because 
$a_1 > a_2$ still applies while $a_3$ has now adapted the path 
$p_{a_3,2} = \{\text{\emph{south east, east, north east}}\}$. The situation 
after adopting $a_3 > a_2$ is shown in \autoref{fig:pca-5}, it shows that $a_2$ 
has a new path $p_{a_2,3} = \{\text{\emph{north east, east, south east}}\}$ 
while $a_3$ has its original path $p_{a_3,1}$. Both of these paths have length 
3 so the conflict is settled in favour of the lower numbered agent, $a_2$ and 
$a_3$ permanently adopt the ordering $a_2 > a_3$.

As a result of the above conflict resolution process each agent now holds part 
of the implied global priority ordering. Agent $a_1$ knows $a_1 > a_2$, agent 
$a_2$ knows $a_1 > a_2$ and $a_2 > a_3$, and $a_3$ knows $a_2 > a_3$. There is 
a global priority ordering $a_1 > a_2 > a_3$ which can only be derived by 
$a_2$, the other two agents have insufficient knowledge to construct the global 
priority ordering.

\subsection{Dialogue-based Partial Cooperative A* (DPCA*)}

\begin{table}
    \centering
    \caption{Stages of a conflict resolution dialogue.}
    \label{tbl:stages}
    \begin{tabular}{l|l|l}
        Stage & Goal & Next stage \\ \hline
        Opening & Exchange information & Proposal \\
        Proposal & Make (incomplete) priority proposals & Evaluation \\
        Evaluation & Vote on suitability of proposals & Proposal, Closing \\
        Closing & Permanently adapt best proposal & \\
    \end{tabular}
\end{table}

PCA* evaluates all possible partial priority orderings for a conflict to obtain 
the most appropriate solution. Doing so can be computationally expensive even 
when only a small number of agents need to be considered. These permutations 
are only evaluated on their increase of solution cost, while they may also have 
other effects on the global state. Some improvements can be made to PCA* so 
that it does not exhaustively search all partial priority orderings while also 
considering their side-effects. Deliberation dialogues can be utilized to 
achieve this.
Agents take part in a dialogue of which the goal is to find a solution to the
conflict that works for all agents involved in the conflict. This dialogue
consists of several stages that are summarised in \autoref{tbl:stages}. There 
is a separate dialogue for each conflict. The agents work through the
conflicts in chronological order, they solve conflicts that occur early before
solving conflicts that occur later. The dialogue replaces lines~6--12 of 
\autoref{alg:pca}. A more complete outline of the dialogue is given in 
\autoref{alg:dpca}.
Each dialogue starts with an opening stage, during this stage the agents notify 
each other if they are taking part
in any dialogues for conflicts that occur earlier than the current conflict
being discussed. If there is such a prior dialogue then the current dialogue
will be put on hold until all earlier dialogues are completed. If the conflict 
of the dialogue is the conflict that occurs the earliest for all involved 
agents then the dialogue moves on to the proposal stage.

\begin{algorithm}[t]
    \caption{Adding deliberation dialogue to PCA*}
    \label{alg:dpca}
    \begin{algorithmic}[1]
        \Require $topic$: conflict that is to be solved by the dialogue
        
        \Comment{Stage 1: opening~~~~}
        
        \If{$topic \neq \Call{EarliestConflict}$}
        \State $\Call{PutDialogueOnHold}$
        \EndIf
        
        \Comment{Stage 2: proposal~~~}
        
        \Repeat
        \State $\Call{Propose}$
        
        \Comment{Stage 3: evaluation}
        
        \ForAll{$proposal \in unevaluatedProposals$}
        \State $path \gets \Call{FindPath}{permanent \cup proposal}$
        \State $vote, expand \gets \Call{Evaluate}{path}$
        \State $\Call{CastVote}{vote}$
        \EndFor
        \Until{$\lnot expand$}
        
        \Comment{Stage 4: closing~~~~}
        
        \State $permanent \gets permanent \cup {\argmin \sum votes}$
    \end{algorithmic}
\end{algorithm}

During the proposal stage each agent can enter a new ordering proposal that is
to be evaluated. Agents can make only one single proposal during each proposal
stage. There can be multiple of these stages during a dialogue so it is
possible for agents to make multiple proposals before the dialogue has
concluded. The proposed priority can be
partial, if there are three or more agents taking part in the dialogue then
$a_1 > a_2 > a_3$ is a valid proposal but $a_1 > a_2, a_3$ is as well. In the
latter case $a_1$ has priority over both $a_2$ and $a_3$, but there is no
established priority ordering between $a_2$ and $a_3$ yet and this may be
decided upon later during the dialogue, or during a future dialogue. Agents
will always propose that they get a higher priority over the other agents that
are part of the conflict. So in a dialogue that involves two agents $a_4$ and
$a_5$ each agent gets to make a proposal, $a_4$ will propose $a_4 > a_5$ while
$a_5$ will propose $a_5 > a_4$. Agents also have the option to not make a 
proposal during this stage.

The third stage is the evaluation stage which is reached when all agents have
made a proposal or declined to make one. Each of the new proposals will be
evaluated in turn. To evaluate a proposed priority ordering the agents 
temporarily adapt it
and update their plans. During this replanning agents have to take into account
the constraints imposed by both the ordering in the proposal, and the ordering
imposed by previously solved conflicts. Once an agent has updated its plan then
it will cast a vote based on how suitable the proposal is. When an agent finds
that it is unable to plan a path to its destination under a certain proposal
then it will notify the other agents of this. In this case the proposal is
rejected by all agents and not voted on, it can also not be expanded on during
an extra proposal stage. If it is not the case that an agent is blocked from
reaching its destination then all agents will show their preference by voting 
on the proposals. Each vote consists of a real number that represents how
suitable the proposal is. This number is based on the increase of the length of
the path, and whether the new plan solves or causes more conflicts at later
time steps. Both of these factors are weighted to result in the final vote. All
agents cast a vote on each acceptable proposal. The proposal with the lowest
sum of the votes is accepted as the solution to the conflict. The votes of each
agents are weighted equally so there is no agent which has a stronger vote.

After all the proposals have been evaluated there is room for agents to claim
to want to expand on previous proposals. If an agent does so then the dialogue
goes through another proposal and evaluation stage. If no agent wants to make
additional proposals the dialogue can be completed in the closing stage. During
the closing stage each agent will permanently adapt the priority scheme with
the highest sum of votes. The priority ordering in this proposal is always
considered when making new proposals and plans during future dialogues. This
completes the dialogue, the agents can now work on conflicts that still occur.
The entire above process is repeated for all conflicts until they are all
solved.

In conflicts that involve three or more agents it is not always the case that a
priority ordering will solve the conflict for all agents. In some conflicts
involving agents $a_1, a_2, a_3$ it may be the case that a partial ordering
$a_1 > a_2, a_3$ means that $a_1$ will not have a conflict with $a_2$ and $a_3$
any more, but that $a_2$ and $a_3$ will still have a conflict at another
position and/or time. In this case either agent can make a request for an
additional proposal round. During this proposal round the agents can make new
proposals or expand on additional proposals. Agents do not need to make
proposals so $a_1$ might not make any new proposals because it already has the
highest priority in the proposal $a_1 > a_2, a_3$. On the other hand $a_2$ and
$a_3$ will propose $a_1 > a_2 > a_3$ and $a_1 > a_3 > a_2$ respectively. After 
all three agents have entered a
proposal or declined to make one the dialogue moves to the evaluation stage
again. This time only the new proposals are evaluated. Any duplicate proposals 
are rejected.
% should not accept expanded proposals

Conflicts that involve more than two agents can be solved in two different
ways. The first is to let agents solve the conflict in pairs, this approach is
known as Dialogue-based Partial Cooperative A* (DPCA*). In a conflict between
the agents $a_1$, $a_2$ and $a_3$ at time $t$ then there would be three
dialogues: one between $a_1$ and $a_2$, one between $a_1$ and $a_3$, and one
between $a_2$ and$a_3$. Say that $a_1$ and $a_2$ are the first to hold a
dialogue which finishes with the priority $a_1 > a_2$, meaning that $a_1$ has
priority over $a_2$. Agent $a_2$ will have found a path that does not go
through the location of the conflict at $t$. This has the effect of also
solving the conflict between $a_2$ and $a_3$. Now only $a_1$ and $a_3$ still
have a conflict at $t$ and they will have to hold a dialogue about which agent
gets priority over the other. When this dialogue would end with the priority
scheme $a_1 > a_3$ then the multi-agent conflict at $t$ is solved. It may be
the case that $a_2$ and $a_3$ now have another conflict at a different position
and/or time that they will have to resolve. For this conflict there will be at
least two dialogues that need to lead to a conclusion, and at most three
conflicts if $a_2$ and $a_3$ do have a conflict at a different location.

The other approach to solving conflicts in which more than two agents are 
involved is to have a single dialogue in which all agents
participate, this is known as Dialogue-based Partial Cooperative A* Plus
(DPCA*+). Having multiple agents in a dialogue will require that the dialogue
supports partial priority orderings and that it allows for multiple rounds of
making proposals and evaluating them. DPCA* does not need to have this
complexity in dialogues. Evaluations are also more complex because agents have 
to weigh whether a proposal solves the conflict for just a subset of the 
involved agents. This is effectively a penalty for a proposal that only 
partially solves the conflict under discussion.
DPCA*+ may be more complex than DPCA*, but it also
requires fewer dialogues to find a set of conflict free paths and therefore it
may be faster than DPCA*.
% result prediction?

Each time that agents evaluate a proposal they have to compute paths that
satisfy the constraints imposed by the priority orderings. This often means
that agents have to recompute the same paths when their priority doesn't change
between proposals. Te reduce the amount of computation required agents can
store the paths that they have calculated. When agents need to calculate a path
to evaluate a proposal they can consult their path cache. This allows them to
use a path that has been found earlier and use that as a solution. The only
restriction is that the cached path does not have a conflict with the paths of
agents that have a higher priority. Some cached paths may cause new additional
conflicts with lower priority agents. This should not stop agents from using
this path because they can solve these conflicts in a later dialogue. Using a
cache should reduce the overall amount of time that is required to find a
conflict free set of paths for all agents.

\subsubsection{Example of dialogue-based conflict resolution}

\begin{figure}
    \centering
    \begin{subfigure}[t]{.3\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/dpca-example1.pdf_tex}
        \caption{Initial configuration showing $p_{a_1,1}$, $p_{a_2,1}$ and 
            $p_{a_3,1}$.}
        \label{fig:example-initial}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{.3\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/dpca-example2.pdf_tex}
        \caption{Configuration after proposal $a_1 > a_2$. Shown are paths 
        $p_{a_1,1}$, $p_{a_2,2}$, $p_{a_3,1}$.}
        \label{fig:example2}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{.3\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/dpca-example3.pdf_tex}
        \caption{Configuration after proposal $a_2 > a_1$. Shown are paths 
        $p_{a_1,2}$, $p_{a_2,1}$, $p_{a_3,1}$.}
        \label{fig:example3}
    \end{subfigure}
    
    \begin{subfigure}[t]{.45\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/dpca-example4.pdf_tex}
        \caption{Configuration after proposal $a_1 > a_3$. Shown are paths 
        $p_{a_1,2}$, $p_{a_2,1}$, $p_{a_3,2}$.}
        \label{fig:example4}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{.45\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/dpca-example5.pdf_tex}
        \caption{Configuration after proposal $a_3 > a_1$. Shown are paths 
        $p_{a_1,3}$, $p_{a_2,1}$, $p_{a_3,1}$.}
        \label{fig:example5}
    \end{subfigure}
    
    \caption{Five stages of resolving a conflict using DPCA*. Agents are 
    circles inscribed
        by $a_i$, their respective goals are $g_i$. Paths that are followed are
        indicated by the arrows. The circles indicate where agents have 
        conflicting moves in their paths.}
    \label{fig:example}
\end{figure}

The cooperative pathfinding problem in \autoref{fig:pca-example} can also be 
solved using DPCA*. This process is outlined using \autoref{fig:example}. The 
problem and the initial paths are equal. After agents share their initial path 
they will find where their paths conflict. Agents $a_1$ and $a_2$ discover that 
they collide after their first action. This means that they will have to 
resolve this conflict to prevent the collision. To allow agents to evaluate 
proposals to solve the conflict we define $\vote_{a_n}(a_i > a_j)$ as 
the vote of agent $a_n$ on the proposal $a_i > a_j$. This represents how 
suitable an agent thinks that a particular proposal is. The evaluation  is 
based on two effects which can be weighted
differently. The first effect is the difference in path length before and after
a proposal has been adopted. The second effect is the change in the number of
conflicts that an agent is involved in, this effect is weighted three times
heavier than the former effect. Qualitatively this means that $\vote_{a_n}(a_i
> a_j) = 1 \cdot \Delta l + 3 \cdot \Delta c$ where $\Delta l$ is the
difference in path cost and $\Delta c$ is the difference in the number of 
conflicts. The 
value of the weights have been arbitrarily picked for demonstration purposes. 
Their value should be set empirically in an implementation.
Agents only communicate their final vote and not how they arrived at it.

Continuing with the example, after the agents have determined that they have a
conflict they start a new dialogue. The dialogue starts in its initial stage;
the opening. All messages are broadcast to all agents in the conflict dialogue,
in this case $a_1$ and $a_2$:
\\ \-\qquad $a_1$: no earlier conflicts
\\ \-\qquad $a_2$: no earlier conflicts

Because both agents don't have any conflicts that occur at an earlier time
(this is the first time step) the dialogue can move on to the proposal stage.
Both agents make a proposal in which they go first:
\\ \-\qquad $a_1$: propose $a_1 > a_2$
\\ \-\qquad $a_2$: propose $a_2 > a_1$

Both agents have made a proposal to resolve the conflict. The dialogue can
move to the evaluation stage. Proposals are evaluated in numerical order of the 
agent that made the proposal so $a_1$'s proposal will be evaluated first. In 
this proposal $a_1$ has the highest priority so it doesn't need to update its 
plan and its path remains $p_{a_1,1}$. It updates $a_2$ of the fact that its 
path hasn't changed and still consists of three consecutive \emph{south} 
actions:
\\ \-\qquad $a_1$: new path
\\ \-\qquad\quad\,\; $p_{a_1,1} = \{\text{\emph{south, south, south}}\}$

Agent $a_2$ does have to yield to $a_1$ so it will have to consider possible 
conflicts that arise with $p_{a_1,1}$ and plan around them. It finds a new path 
$p_{a_2,2} = \{\text{\emph{south east, east, north east}}\}$ which is shown in 
\autoref{fig:example2}. After finding the new path $a_2$ will evaluate its 
quality so that it can send its vote to $a_1$. After adopting the proposal 
$a_2$ now has two conflicts with $a_3$ so $\Delta c = 1$. There is no 
difference in the length of the paths before and after temporarily adopting the 
constraints of the proposal so $\Delta l = 0$. This means that $a_2$ can send 
the vote to $a_1$. It will send its new path along with the evaluation:
\\ \-\qquad $a_2$: new path
\\ \-\qquad\quad\,\; $p_{a_2,2} = \{\text{\emph{south east, east, north 
east}}\}$
\\ \-\qquad $a_2$: $\vote_{a_2}(a_1 > a_2) = 3$

Now that $a_1$ knows the new path of agent $a_2$ after adopting to $a_1 > a_2$
it can also vote on the proposal. This happens in a similar vein as $a_2$'s
evaluation. Agent $a_1$ has no more conflicts while it had one previous 
conflict so $\Delta c = -1$. The vote for this proposal can then be cast:
\\ \-\qquad $a_1$: $\vote_{a_1}(a_1 > a_2) = -3$

Now that this proposal has been evaluated by both agents they can find the sum
score of the proposal which is $\eval(a_2 > a_1) = \eval(a_1, a_1 > a_2) +
\eval(a_2, a_1 > a_2) = 0$. Next the agents can evaluate $a_2 > a_1$. When 
agent $a_1$ goes to evaluate this conflict if finds that it will have to wait 
for $a_2$ to send a new path because $a_2$ currently has a temporary path. 
Agent $a_2$ can use the path $p_{a_2,1}$ which is stored in its cache, it sends 
this information to $a_1$:
\\ \-\qquad $a_2$: new path
\\ \-\qquad\quad\,\; $p_{a_2,1} = \{\text{\emph{east, east, east}}\}$

Next $a_1$ can evaluate the proposal. First it needs to make a new plan that 
does not conflict with the path that $a_2$ has just sent. It finds the path 
$p_{a_1,2} = \{\text{\emph{south east, south, south west}}\}$. This new 
situation is shown in \autoref{fig:example3}. Agent $a_1$ can immediately 
evaluate it, the lengths of $p_{a_1,1}$ and $p_{a_1,2}$ are equal and there is 
an equal amount of conflicts. The new path and the evaluation are communicated 
with $a_2$:
\\ \-\qquad $a_1$: new path
\\ \-\qquad\quad\,\; $p_{a_1,2} = \{\text{\emph{south east, south, south 
west}}\}$
\\ \-\qquad $a_1$: $\vote_{a_1}(a_2 > a_1) = 0$

Now that $a_2$ knows $a_1$'s new plan it can also send its evaluation which has 
one fewer conflict than its original path:
\\ \-\qquad $a_2$: $\vote_{a_2}(a_2 > a1) = -3$

Now both agents have evaluated the proposal $a_2 > a_1$ they can find the sum 
of the evaluations which is $\vote(a_2 > a_1) = \vote_{a_1}(a_2 > a_1) + 
\vote_{a_2} = -3$. All proposals have been evaluated so the agents can notify 
each other if they want to make further proposals:
\\ \-\quad $a_1$: no further proposals
\\ \-\quad $a_2$: no further proposals

Neither agent wants to make more priority ordering proposals. This is because 
there are no more possible priority orderings to make with these two agents. 
The dialogue can then move to the closing stage. In the closing stage agents 
will pick the best proposal, in this case that is the proposal with minimal 
sum score which is the proposal $a_2 > a_1$ (\autoref{fig:example3}). To adapt 
this proposal agents will need to use the respective paths that they used 
during the evaluation of the proposal. So $a_1$'s path will be $p_{a_1,2}$ and 
$a_2$'s path will be $p_{a_2,1}$. They also need to keep track of which agents 
have a higher priority than themselves. Agent $a_1$ must now store that $a_2$ 
has a higher priority while $a_2$ does not have to store anything. Both agents 
also communicate their new path with all other agents, in \autoref{fig:example} 
this is only agent $a_3$.

After the new path have been evaluated $a_1$ and $a_3$ notice that they have a 
conflict. Their dialogue is as follows:

Opening stage
\\ \-\qquad $a_1$: no earlier conflicts
\\ \-\qquad $a_3$: no earlier conflicts

Proposal stage
\\ \-\qquad $a_1$: propose $a_1 > a_3$
\\ \-\qquad $a_3$: propose $a_3 > a_1$

Evaluation stage, starting with $a_1 > a_3$, new paths are shown in 
\autoref{fig:example4}
\\ \-\qquad $a_1$: new path
\\ \-\qquad\quad\,\; $p_{a_1,2} = \{\text{\emph{south east, south, south 
west}}\}$
\\ \-\qquad $a_3$: new path
\\ \-\qquad\quad\,\; $p_{a_3,2} = \{\text{\emph{south east, east, north 
east}}\}$
\\ \-\qquad $a_3$: $\vote_{a_3}(a_1 > a_3) = -3$
\\ \-\qquad $a_1$: $\vote_{a_1}(a_1 > a_3) = -3$

 Evaluation of $a_3 > a_1$, new paths are shown in \autoref{fig:example5}
\\ \-\qquad $a_3$: new path
\\ \-\qquad\quad\,\; $p_{a_3,1} = \{\text{\emph{east, east, east}}\}$
\\ \-\qquad $a_1$: new path
\\ \-\qquad\quad\,\; $p_{a_1,3} = \{\text{\emph{south west, south, south 
east}}\}$
\\ \-\qquad $a_1$: $\vote_{a_1}(a_3 > a_1) = -3$
\\ \-\qquad $a_3$: $\vote_{a_3}(a_3 > a_1) = -3$

Both proposals have a sum score of $-6$ so we break the tie in favour of $a_1$, 
$a_1 > 
a_3$ is permanently adapted by both agents. The final paths $p_{a_1,2}$ and 
$p_{a_3,2}$ are communicated with $a_2$ and there are no more conflicts. A 
valid solution as been found: $a_1 > a_3$ and $a_2 > a_1$.

DPCA* finds a different solution than PCA* because it takes the number of 
conflicts in a partial solution into account. Because of this it finds a 
different solution to the conflict between $a_1$ and $a_2$. DPCA* also added 
more transparency to the process by showing why agents picked a certain 
solution to a conflict. In contrast PCA* is opaque, the result was mainly 
determined by how ties between equal priority orderings are broken.

\subsection{Windowed Dialogue-based Partial Cooperative A* (WDPCA*)}
DPCA* and DPCA*+ have to compute the entire solution before it can be executed.
Planning and execution both take time
without requiring the same resources making it possible to do them at the
same time. This means that the plan can be executed while it is still being
constructed. One way of doing this is by applying a window to restrict how far
away from an agent's location DPCA* will be used to solve conflicts. A
window $w$ determines that agents will use the above algorithm to solve all
conflicts that occur within $w$ time steps from their current position. Agents
will not cooperate past the boundary of the window, solving conflicts that
happen beyond that border is deferred to a later point in time. Periodically
the agents will update the conflicts that occur within their window and solve 
them.
Because agents only coordinate in the window it is not necessary for them to
plan a path past the window boundary as well. Instead agents can plan a path
for the next $w$ time steps so they get closer to their goal. To achieve this
the graph can be changed so that the nodes at the window boundary connect
directly to the goal node. This can be achieved by changing the cost function
defined in \autoref{sec:problem} between adjacent nodes $P$ and $Q$
\cite{silver2005}
\[
\text{\textsc{cost}(P,Q)} =
\begin{cases}
    0 & \text{if } P = Q = G, t < w \\
    \textsc{HeuristicDistance(P,G)} & \text{if } t = w \\
    1 & \text{otherwise}
\end{cases}
\]
where \textsc{HeuristicDistance} is a function that returns the cost of the
shortest path between $P$ and $G$ as if there are no other agents on the graph.

Using the window spreads out the computation over the course of execution, but
it has other benefits as well. Exchanging optimal paths between agents after
the first step may take a long time in large multi-agent systems.
By limiting the search using a window agents only need to coordinate with a
limited number of other agents. This reduces
the initial planning time, as well as for each subsequent window. Agents that
are never in each other's window will never have to communicate with each other,
saving a lot of unnecessary communication and conflict detection overhead.
Windowing the search also has benefits in systems where agents can change their
destination during execution. Instead of recalculating the entire plan when
this happens, only agents within the window of the agent changing destination
have to update their plan. Agents that are not affected by the change in
destination do not have to update their plan. When there would be no window all
agents would have to recalculate and solve all conflicts again, even if they
would not need to update their plan, leading to wasted computational resources.

An online algorithm like WDPCA* has the implied effect of forcing agents to 
abide the consequences of interleaving planning and execution. It is not 
desirable for agents to backtrack long distances to solve a conflict that 
occurs late in execution because it would drastically increase the solution 
cost. Instead agents will have to deal with the consequences when they occur. 
This fits with the philosophy of partial global planning where a solution is 
incrementally arrived at. By employing a window agents will set parts of their 
plan in stone while keeping future actions flexible. This is similar to how 
partial global planning enforces agreed upon coordination but allows agents 
flexibility in the details of their plan.

\subsubsection{Example of dialogue-based conflict resolution}
\begin{figure}
    \centering
    \begin{subfigure}[t]{.3\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/wdpca-example1.pdf_tex}
        \caption{Initial configuration showing $p_{a_1,1}$, $p_{a_2,1}$ and 
            $p_{a_3,1}$.}
        \label{fig:wdpca-example1}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{.3\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/wdpca-example2.pdf_tex}
        \caption{Configuration after proposal $a_1 > a_2$. Shown are paths 
            $p_{a_1,1}$, $p_{a_2,2}$, $p_{a_3,1}$.}
        \label{fig:wdpca-example2}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{.3\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/wdpca-example3.pdf_tex}
        \caption{Configuration after proposal $a_2 > a_1$. Shown are paths 
            $p_{a_1,2}$, $p_{a_2,1}$, $p_{a_3,1}$.}
        \label{fig:wdpca-example3}
    \end{subfigure}
    
    \begin{subfigure}[t]{.4\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/wdpca-example-t0-3.pdf_tex}
        \caption{Configuration after proposal $a_1 > a_3$. Shown are paths 
            $p_{a_1,2}$, $p_{a_2,1}$, $p_{a_3,2}$.}
        \label{fig:wdpca-example4}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{.4\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/wdpca-example-t0-4.pdf_tex}
        \caption{Configuration after proposal $a_3 > a_1$. Shown are paths 
            $p_{a_1,3}$, $p_{a_2,1}$, $p_{a_3,1}$.}
        \label{fig:wdpca-example5}
    \end{subfigure}

    \begin{subfigure}[t]{.4\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/wdpca-example-t1.pdf_tex}
        \caption{Configuration after agents execute half of their plan 
        ($p_{a_1,2}, p_{a_2,1}, p_{a_3,2})$.}
        \label{fig:wdpca-example6}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{.4\textwidth}
        \centering
        \def\svgscale{.6}
        \input{images/wdpca-example-t2.pdf_tex}
        \caption{Configuration after agents have executed half of their plan 
        for the second timestep.}
        \label{fig:wdpca-example7}
    \end{subfigure}
    
    \caption{Seven stages of resolving a conflict using WDPCA*. Agents are 
        circles inscribed
        by $a_i$, their respective goals are $g_i$. Paths that are followed are
        indicated by the arrows. The circles indicate where agents have 
        conflicting moves in their paths.}
    \label{fig:wdpca-example}
\end{figure}

The same situation as in \autoref{fig:pca-example} and \autoref{fig:example} 
can also be solved by WDPCA*. This process is shown in 
\autoref{fig:wdpca-example}. For this example the window size is set to two ($w 
= 2$), 
agents always make plans of two steps. Initially agents $a_1$ and $a_2$ have a 
conflict, their dialogue:

Opening stage
\\ \-\qquad $a_1$: no earlier conflict
\\ \-\qquad $a_2$: no earlier conflict

Proposal stage
\\ \-\qquad $a_1$: propose $a_1 > a_2$
\\ \-\qquad $a_2$: propose $a_2 > a_1$

Evaluation stage, starting with $a_1 > a_2$, new paths are shown in 
\autoref{fig:wdpca-example2}
\\ \-\qquad $a_1$: new path
\\ \-\qquad\quad\,\; $p_{a_1,1} = \{\text{\emph{south, south}}\}$
\\ \-\qquad $a_2$: new path
\\ \-\qquad\quad\,\; $p_{a_2,2} = \{\text{\emph{south east, east}}\}$
\\ \-\qquad $a_2$: $\vote_{a_2}{a_1 > a_2} = 3$
\\ \-\qquad $a_1$: $\vote_{a_1}{a_1 > a_2} = -3$

Evaluation of $a_2 > a_1$, new paths are shown in \autoref{fig:wdpca-example3}
\\ \-\qquad $a_2$: new path
\\ \-\qquad\quad\,\; $p_{a_2,1} = \{\text{\emph{east, east}}\}$
\\ \-\qquad $a_1$: new path
\\ \-\qquad\quad\,\; $p_{a_1,2} = \{\text{\emph{south east, south}}\}$
\\ \-\qquad $a_1$: $\vote{a_1}{a_2 > a_1} = 0$
\\ \-\qquad $a_2$: $\vote{a_2}{a_2 > a_1} = -3$

The solution to the conflict in \autoref{fig:wdpca-example1} is $a_2 > a_1$. 
The new conflict between $a_1$ and $a_3$ is solved with the following dialogue:

Opening stage
\\ \-\qquad $a_1$: no earlier conflict
\\ \-\qquad $a_3$: no earlier conflict

Proposal stage
\\ \-\qquad $a_1$: propose $a_1 > a_3$
\\ \-\qquad $a_3$: propose $a_3 > a_1$

Evaluation stage, starting with $a_1 > a_3$, new paths are shown in 
\autoref{fig:wdpca-example4}
\\ \-\qquad $a_1$: new path
\\ \-\qquad\quad\,\; $p_{a_1,2} = \{\text{\emph{south east, south}}\}$
\\ \-\qquad $a_2$: new path
\\ \-\qquad\quad\,\; $p_{a_3,2} = \{\text{\emph{south east, east}}\}$
\\ \-\qquad $a_2$: $\vote_{a_3}{a_1 > a_3} = -3$
\\ \-\qquad $a_1$: $\vote_{a_1}{a_1 > a_3} = -3$

Evaluation of $a_3 > a_1$, new paths are shown in \autoref{fig:wdpca-example5}
\\ \-\qquad $a_3$: new path
\\ \-\qquad\quad\,\; $p_{a_3,1} = \{\text{\emph{east, east}}\}$
\\ \-\qquad $a_1$: new path
\\ \-\qquad\quad\,\; $p_{a_1,3} = \{\text{\emph{south west, south}}\}$
\\ \-\qquad $a_1$: $\vote{a_1}{a_2 > a_1} = -3$
\\ \-\qquad $a_2$: $\vote{a_2}{a_2 > a_1} = -3$

Both proposals have been evaluated equally so we break the tie in favour of 
$a_1$. The priority orderings for the first time step are $a_2 > a_1$ and $a_1 
> a_3$. The agents now execute half of their plan, in this case that is one 
time step ($w/2$). After executing half of their plan the agents discard the 
priority orders $a_2 > a_1$ and $a_1 > a_3$ and they make new plans for the 
next 2 time steps. These new plans are shown in \autoref{fig:wdpca-example6}. 
There are no conflicts so no dialogues need to bee held. Agents execute the 
first step of their plans and make new plans. The situation at the next time 
step is shown in \autoref{fig:wdpca-example7}. There are again no conflicts. 
After all agents execute the first action in their plan they have all reached 
their goal and this instance of the cooperative pathfinding problem has been 
solved.

\subsection{Summary}
An overview of all proposed algorithms is given in \autoref{tbl:proposed}, the
categories shown the same as those in \autoref{tbl:planning-overview}. Some
of the columns from \autoref{tbl:planning-overview} are missing in
\autoref{tbl:proposed} because these have the same values for all proposed
algorithms. Each algorithm is decentralized since they do not rely on a
central processor at any time. The algorithms are heavily influenced by the
decoupled approach where agents first calculate optimal routes, then
find a priority ordering and finally plan a route to their destination that
adhere to the constraints that are imposed by the priority ordering. None of
the methods is complete because they belong to categories that generally do not
include complete algorithms. The meaning of the ``communication'' and 
``online'' columns is the same as in \autoref{tbl:planning-overview}. The 
``dialogues'' column is new, it indicates whether agents can propose solutions, 
argue about them and share evaluations on the proposals.

\begin{table}
    \centering
    \caption{Comparison of proposed cooperative pathfinding algorithms. The
    communication and online columns are the same as those in
    \autoref{tbl:planning-overview}.}
    \label{tbl:proposed}
    \begin{tabular}{l|l|l|l}
        Algorithm & Communication & Online & Dialogues \\ \hline
        PCA*   & All & No & No \\
        DPCA*  & All & No & Yes \\
        WDPCA* & Window & Yes & Yes \\
    \end{tabular}
\end{table}