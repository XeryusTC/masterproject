\section{Introduction}\label{sec:intro}
Path planning for a single agent is considered a solved problem
\cite{sharon2013}. When multiple agents have to find their way through a
shared
space then the problem becomes more complicated. The agents have to find paths
around obstacles while they also need to ensure that they do not collide with
each other. Even when agents can prevent collisions then it is still possible
that congestions or even deadlocks may occur. To avoid these undesirable
situations there is a need for coordination between the agents. This problem is
addresd in the studo of what is called cooperative pathfinding. It finds its
application in robotics, aviation, road traffic management, crowd simulations,
and video games \cite{standley2011}.

An agent in the cooperative pathfinding problem can make one of $b+1$ moves 
during each discrete time step. It can move to any of $b$ neighbouring nodes on 
the graph or it can \emph{wait} in its current position. The most 
straightforward 
solution to the problem is search the Cartesian products of all these state 
spaces. This is computationally inefficient \cite{hopcroft1984,sharon2013} as 
the branching factor of the new state space is $(b+1)^k$ where $k$ is the 
number of agents in the problem. Centralized algorithms try to control the 
state space explosion by efficiently calculating paths for all agents on a 
single processor. Operator Decomposition and Independence Detection (OD+ID) 
\cite{standley2010,standley2011} control the state space explosion by 
assigning each agent an action individually instead of taking the Cartesian 
product of their state spaces. This reduces the branching factor to $(b+1)$ but 
the depth of the solution in the search tree grows with a linear factor $k$. 
This makes the search more tractable with conventional search algorithms like 
A*. Additionally the problem is split into independent sub-problems.
\cite{standley2010} found that the runtime is dominated by finding a solution 
for the largest subgroup. The algorithm is both complete and optimal; it will 
always find a solution to the problem if it exists and it will find the lowest 
cost solution to do so. Another centralized method is the Increasing Cost Tree 
Search (ICTS) \cite{sharon2013} which searches combinations of increasingly 
longer paths for all agents. ICTS is faster than OD+ID in situations when the 
number of agents relative to the number of nodes is high.

Another common approach to the cooperative pathfinding problem is to decouple 
the agents from each other. This means that each agent individually finds it 
optimal path. This approach forgoes completeness for the sake of speed. 
Usually this is done by imposing a hierarchy on the agents. Agents need to 
consider agents with a higher priority as moving obstacles. Each agent has a 
unique rank in the priority order. Finding the best priority ordering is a 
combinatorial problem. Dependencies between the optimal paths of agents can be
used to decrease the search space 
\cite{bennewitz2002}. Often finding the priority scheme is done on a central 
processor but the calculation of the paths for agents can be decentral. One 
method which does so is Interruptible Asynchronous Decentralized Path Planning 
(IADPP) \cite{cap2012}. When agents have been assigned a priority they can 
start planning at 
the same time. When an agent is finished it will send its path to all lower 
priority agents. When an agent receives a conflicting path then it will restart 
planning while taking the path of the higher priority 
agent into account. Windowed Hierarchical Cooperative A* (WHCA*) 
\cite{silver2005} is an algorithm that has been successful in the gaming 
industry. It is an online algorithm which interleaves planning and execution. 
It does this by forcing agents to plan cooperatively in a time window. Actions 
that occur outside of that time window do not have to take other agents into 
account. During execution agents will regularly make a new plan. This allows 
the priority order to vary over the course of 
execution. It also allows agents to continue cooperating after they have 
reached their goal.

It is also possible to tackle the cooperative pathfinding problem without the 
use of a central processor. A method called Decentralized Multi-Robot 
Cooperative Pathfinding (DMRCP) \cite{wei2016} restricts the 
range of communication between agents to a two graph node radius. Within this 
range agents use various coordination strategies to avoid conflicts. Because of 
the limited communication range there is an increased risk of congestions and 
deadlocks which require special strategies to be resolved. Although 
completeness is not discussed the algorithm is based on decoupled methods which 
are generally not complete. DMRCP requires less time to find a solution than 
OD+ID. Another algorithm that doesn't use a central processor is Distributed 
Multi-agent Path Planning (DiMPP) \cite{chouhan2017}. The authors claim that 
this distributed algorithm is complete. Instead of evaluating 
$k!$ possible priority schemes the algorithm evaluates at most $k$ orders. Each 
priority order has a different agent with the highest priority, but the agents 
always occur in the same order. Agents work on a plan in the order that they 
occur in the priority scheme. If they cannot find a path to their destination 
then they will drop that plan. Once a complete plan has been found all agents 
can start executing it.

% Argumentation
Methods of decentralised multi-agent coordination have been developed by the 
field of
computational argumentation. Formal models of argumentation have been used in
Artificial Intelligence in expert systems, multi-agent systems and law
\cite{vaneemeren2014}. A pillar of argumentation is that of non-monotonic 
logic. A logic is non-monotonic when a conclusion that follows from a set of 
premises does not necessarily hold when additional premises are 
added to the set \cite{modgil2013,vaneemeren2014}. 
Pollock~\shortcite{pollock1995} has 
constructed an agent called OSCAR which is able to pursue goals and it will 
stop doing so once it has deemed that they are unachievable. 

Argumentation in multi-agent systems is often done through dialogues. These are 
games in which the agents are players and the moves that they can make are 
certain utterances. The rules of the game can determine how to start 
and end the dialogue, which agent gets to speak when, which utterances agents 
can make, and what the outcome is and which agent(s) have won the dialogue if 
applicable. Walton~\shortcite{walton1995} proposed a typology of the six main 
dialogues 
that humans partake in. Deliberation dialogues allow agents to settle on a 
common course of action. One theory of deliberation dialogue has been 
influential, we will refer to it as the MHP model \cite{mcburney2007}. It 
consists of eight stages in which the agents will collect the preferences, 
goals and other constraints that need to be considered. Agents propose plans, 
make recommendations, evaluate plans, and eventually pick the most appropriate 
plan. Agents need to unanimously accept a plan to come to a successful 
solution, but the MHP model also allows for a voting mechanism. Several 
shortcomings of the MHP model have been addressed by 
Walton~\shortcite{walton2014}. It 
introduces new end-conditions and improves the way that additional information 
can be integrated. The \textsc{TeamLog} model \cite{dunin-keplicz2011} 
simplifies the MHP model by condensing the six stages where argumentation takes 
place into two stages. These are the proposal stage where agents can introduce 
plans and the evaluation stage in which agents evaluate and vote on proposals. 
The model is meant to be used in autonomous agents while the MHP model also 
tries to model human deliberation dialogues.
\textsc{TeamLog} still has the same richness in dialogue as the MHP model.

% PGP
Without a central processor it is hard to create a plan that is globally well
coordinated. Partial global planning (PGP) has been used in distributed sensor
networks to distribute and coordinate tasks among the nodes that make up the
network \cite[pp.~202--204]{durfee1991,woodridge2009}. The nodes create their 
individual plans without
regard for each other. They will then exchange information on their plans and
adapt them to better coordinate their activities. They do this by incrementally 
adapting their plans to those of other agents. Coordination is not rigid and
nodes are free to change their plan when circumstances change without the need 
to re-coordinate with the other nodes. None of the involved nodes ever has a 
global view, but the end result is a plan that is globally well
coordinated with each node holding the part of the global plan that is relevant
to it. Generalized PGP \cite{decker1992} extends this with real-time planning, 
negotiation and coordination relationships between goals. This allows the 
framework to be used in other multi-agent coordination tasks.

% describe how to combine these three views
Dialogues can be used in cooperative pathfinding by applying techniques from
partial global planning. Agents can resolve conflicts by starting a dialogue in
which they share and evaluate different hypothesis to solve the conflict. A
hypothesis consists of a priority ordering for the agents that are involved in
the conflict. The hypotheses offered will be discussed and evaluated in the
dialogue and the agents will select the best proposal as the solution
to the conflict. All agents involved in the dialogue adapt the priority
ordering and adopt their plan to it. This means that there are many small local
changes to an agent's position in the global hierarchy and therefore also in
their plans. The end result is a global solution to the cooperative pathfinding
problem without any agent having known it explicitly. There is also no single
agent which has been vital to its calculation like in a centralized approach.

The rest of this article is structured as follows. First, a formal description
of the cooperative pathfinding problem is given in \autoref{sec:problem}.
A family of methods to find
conflict-free paths is proposed in \autoref{sec:method}. The method is
evaluated and compared to other algorithms in \autoref{sec:results}. Final
remarks on the proposed method and its implications are discussed in
\autoref{sec:discussion}.
