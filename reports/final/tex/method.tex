\section{Algorithm}\label{sec:method}
Decoupled algorithms are able to solve cooperative pathfinding problems while
requiring only minimal resources. The agents calculate paths to their
destination individually so this is inherently distributed. To achieve this
there has to be determine a  priority order for the agents so that they can
plan paths that have no conflicts. To do this there is often a central
processor that knows the optimal paths of all agents. This central processor
can then
find dependencies between agents to determine possible priority orderings that
can be used to solve the problem \cite{latombe1991,bennewitz2002}. This means
that decoupled methods are almost fully distributed but they have a single
centralized bottleneck. All agents will have to halt calculating a solution
while the priority scheme is determined by the central processor.

To overcome this bottleneck the calculation of the priority ordering can also
become distributed. The three step base decoupled method can be
altered to allow for this, the first step where each agent plans its optimal
path without regard for the other agents remains the same. Next agents share
the paths that they found with each other. Each agent can now determine where
its path and the paths of other agents
have conflicting moves that would lead to a collision. The agents will then be
able to solve the conflicts without having to wait for slower agents to
calculate and communicate their optimal paths. To solve conflicts agents will
start a dialogue where possible solutions are proposed, evaluated and adapted.
The proposals made consist of a priority order for the agents involved in the
conflict. Agents will only need to solve the first conflict that occurs in
their path because solving it may have the side-effect of solving later
conflicts. After a conflict has been successfully solved then the agents
involved can work on solving the next conflict.
Below are the details of three different versions of this algorithm, each
version of the algorithm has some improvements over the previous version.

%Each of the three algorithms builds upon a more general search algorithm
%Cooperative A* (CA*). This algorithm is a variation on A* \cite{hart1968} that
%allows teams of agents to cooperate. Each agent searches for a path
%individually, but they can take each other's actions into account. Both space
%and time are searched so that the movements of other agents can be considered.
%Agents send their paths to the other agents once they're found. During the
%neighbouring node expansion stage of A*

\subsection{Partial Cooperative A*}
The heart of the algorithm is the conflict resolution step. The most
straightforward approach to solving conflicts is by going through all possible
agent orderings. An ordering determines which agent has priority over another
agent, the ordering $a_1 > a_2$ indicates that $a_1$ can plan freely while
$a_2$ has to consider $a_1$ as a moving obstacle. Usually decoupled methods use
a permutation of the priority ordering $a_1 > a_2 > \ldots > a_k$ that all
agents have to adhere to. Partial Cooperative A* (PCA*) uses the method
described above to allow agents to communicate conflicts with each other. When
agents detect that they have a conflict they will try to find a priority
ordering between them that will solve the conflict. Agents will always try to
find a solution to the conflict that is closest to their current position
first. This is because the solution to earlier occurring conflicts may also
have the effect of solving or creating later conflicts.

To find the most suitable priority ordering scheme all possible orderings
between the agents that are involved in the conflict are evaluated. So a
conflict with two agents will result in the ordering $a_1 > a_2$ and $a_2 >
a_1$. The agents temporarily adapt the first ordering and plan new paths with
the constraints it introduces, the agents measure the length of the paths that
they found. Next they will adapt the second ordering and create a new plan
using its constraints, they also measure the lengths. The priority scheme for
which the sum of the path lengths is the lowest is permanently adapted by the
agents. Because the solution with the lowest sum path length is used there is
no consideration for the effects of the solution of conflicts that occur later.

Only the agents that occur in a priority ordering adapt it. This means that an
agent $a_3$ does not know about the ordering that agents $a_1$ and $a_2$ have
settled on, say that they picked $a_2 > a_1$. When $a_3$ and $a_1$ have a
conflict then this will also find a solution to it. If they settle on a
solution $a_1 > a_3$ then only $a_1$ knows $a_2 > a_1 > a_3$, the other two
agents only know the partial priorities. In this case the global priority is
known by $a_1$, but it will not always be the case that one agent knows the
full priority ordering. The ordering is implied by the partial orderings that
the agents do know about, this is similar to how plans are constructed in
partial global planning.
% TODO: incremental plans

The orderings that are found do not need to be unambiguous, if $a_1$ and $a_3$
had used the solution $a_3 > a_1$ then $a_1$ would have orderings $a_2 > a_1$
and $a_3 > a_1$ but no $a_2 > a_3$ or $a_3 > a_2$. This leaves $a_2$ and $a_3$
free to use any priority scheme in the event that they also have a conflict in
their paths. This also allows for circular priority orderings, something which
conventional decoupled algorithms do not support. This is possible because the
circular ordering is implicit in all the partial orderings that individual
agents know about. The implied global priority also doesn't need to be
complete, not every agent needs to be present in it. This is easiest to see
when considering only agents $a_1$ and $a_5$ in \autoref{fig:world}, for this
example the other agents do not exist. There is no need to establish an
ordering for these two agents since their paths never meet. This has the effect
of implied Independence Detection \cite{standley2010} because these agents will
never have to communicate beyond sharing the paths that they have found with
each other. There is no need for them to coordinate because their plans never
interact.
% Simplicity of algorithm b/c not able to predict consequences
% priorities form PGP

%The simplest approach to resolving the conflicts is by creating all possible
%ordering permutations for the agents involved in the conflict. The permutation
%that has the lowest sum path length is used as the solution for the conflict.
%This simple method of evaluating the various solutions is unlikely to find the
%most appropriate one because it is not able to predict the consequences of
%selecting one solution over the others.
%Most conflicts involve just two agents, so there are only two possible ordering
%permutations which means that the amount of priority permutations that need to
%be evaluated is low.

\subsection{Dialogue-based Partial Cooperative A*}
\begin{table}
    \centering
    \caption{Stages of a conflict resolution dialogue.}
    \label{tbl:stages}
    \begin{tabular}{l|l|l}
        Stage & Goal & Next stage \\ \hline
        Opening & Exchange information & Proposal \\
        Proposal & Make (incomplete) priority proposals & Evaluation \\
        Evaluation & Vote on suitability of proposals & Proposal, Closing \\
        Closing & Permanently adapt best proposal & \\
    \end{tabular}
\end{table}

Going through all possible permutations and evaluating them on a single
criterion is not the most clever method of finding a priority ordering
\cite{bennewitz2002}. This would mean that the entire search space is
exhaustively examined until a working solution is found. To avoid evaluating
all possible permutations and thereby reducing the time required to find a
solution some improvements can be made. Utilising a dialogue to solve conflicts
can reduce the number of priority combinations that need to be evaluated.
Agents take part in a dialogue of which the goal is to find a solution to the
conflict that works for all agents involved in the conflict. This dialogue
consists of several stages which are summarised in \autoref{tbl:stages}. For
each conflict the agents start a new dialogue. The agents work through the
conflicts in chronological order, they solve conflicts that occur early before
solving conflicts that occur later. The opening stage is where each dialogue
starts, during this stage the agents notify each other if they are taking part
in any dialogues for conflicts that occur earlier than the current conflict
being discussed. If there is such a prior dialogue then the current dialogue
will be put on hold all earlier dialogues are completed. If the conflict that
the dialogue is on is the earliest conflict for all involved agents then the
dialogue moves on to the proposal stage.

During the proposal stage each agent can enter a new ordering proposal that is
to be evaluated. Agents can make only one single proposal during each proposal
stage. There can be multiple of these stages during a dialogue so it is
possible for agents to make multiple proposals before the dialogue has
concluded. The proposed priority can be
partial, if there are three or more agents taking part of the dialogue then
$a_1 > a_2 > a_3$ is a valid proposal but $a_1 > a_2, a_3$ is as well. In the
latter case $a_1$ has priority over both $a_2$ and $a_3$, but there is no
established priority ordering between $a_2$ and $a_3$ yet and this may be
decided upon later during the dialogue, or during a future dialogue. Agents
will always propose that they get a higher priority over the other agents that
are part of the conflict. So in a dialogue that involves two agents $a_4$ and
$a_5$ each agent gets to make a proposal, $a_4$ will propose $a_4 > a_5$ while
$a_5$ will propose $a_5 > a_4$.

The third stage is the evaluation stage which is reached when all agents have
made a proposal or declined to make one. Each of the new proposals will be
evaluated in turn. To evaluate a proposed priority ordering the agents adapt it
and update their plans. During this replanning agents have to take into account
the constraints imposed by both the ordering in the proposal, and the ordering
imposed by previously solved conflicts. Once an agent has updated its plan then
it will cast a vote based on how suitable the proposal is. When an agent finds
that it is unable to plan a path to its destination under a certain proposal
then it will notify the other agents of this. In this case the proposal is
rejected by all agents and not voted on, it can also not be expanded on during
an extra proposal stage. If it is not the case that an agent is blocked from
reaching its destination then all agents will vote on their preference for a
proposal. Each vote consists of a single real number that represents how
suitable the proposal is. This number is based on the increase of the length of
the path, and whether the new plan solves or causes more conflicts at later
time steps. Both of these factors are weighted to result in the final vote. All
agents cast a vote on each acceptable proposal. The proposal with the highest
sum of the votes is accepted as the solution to the conflict. The votes of each
agents are weighted equally, so there is no agent which has a stronger vote.

% additional proposal stages
% multiple agents
% Closing stage

%During the evaluation of a proposal each agent has to update
%their plan, the restrictions imposed by the ordering of the proposal should be
%respected, as well as the restrictions imposed by previously solved conflicts.
%Once an
%agent is done with updating its plan then it will cast a vote based on how
%suitable the proposal is. All votes are collected and the best proposal is
%used as the solution. It is also possible that an agent was blocked from
%reaching its destination with the proposed priorities, in this case an agent
%can also notify the other agents of this and the proposal is rejected.
%
%When multiple agents are involved then it is possible that a proposal can not
%be solved by giving one agent priority over all the others, in this case a more
%complete priority ordering is required. If this happens then the dialogue will
%have another proposal stage. Agents will now be allowed to expand on earlier
%proposals as well as making completely new proposals. Afterwards there is
%another evaluation stage.
%
%After each evaluation stage the agents will tell each other whether they want
%to make additional proposals. If none of the agents does so then the dialogue
%moves to the closing stage. During the closing stage the proposal with the most
%votes is selected as the solution for the conflict. All agents that took part
%in the dialogue permanently adapt the priority ordering. After the dialogue is
%finished the agents will start working on resolving any further conflicts that
%they may have. As a result of resolving conflict agent's plans may have been
%changed, so they will have to communicate their updated plans to the other
%agents, they will also have to recalculate where and when conflicts in their
%plans occur.

There are two approaches to solving conflicts that involve multiple agents. The
first is to have a single dialogue for all agents, this is referred to as
Dialogue-based Partial Cooperative A* Plus (DPCA*+). Another approach is to let
agents solve conflicts in pairs only. If there is a conflict between agents
$a_1$, $a_2$, $a_3$ at time $t$ then there would be three dialogues: one
between $a_1$ and $a_2$, one between $a_1$ and $a_3$, and one between $a_2$ and
$a_3$. Say $a_1$ and $a_2$ are first to hold a dialogue which finishes with the
priority $a_1 > a_2$, meaning that $a_1$ has priority over $a_2$. $a_2$ is then
routed away from the conflict location. Next $a_1$ and $a_3$ will have to
resolve their remaining conflict. When this is also resolved as $a_1 > a_3$
then the conflict at $t$ is solved. It may be the case that $a_2$ and $a_3$ now
have a conflict at another position and they will have to solve this as well.
This algorithm is called Dialogue-based Partial Cooperative A* (DPCA*). This
approach of having multiple smaller dialogues can be faster than having a
single large complex dialogue.

To reduce the amount of computation required agents can store the paths that
they have calculated. Agents can then consult their path cache when evaluating
proposals. This allows them to pick a path that has been found earlier and use
that as a solution. The only restriction is that the cached path does not have
a conflict with agents of a higher priority. Using a cached path may increase
the number of conflicts, these will be solved by later dialogues and do not
influence the use of a cached path.

\subsection{Windowed Dialogue-based Partial Cooperative A*}
One of the issues with this algorithm is that all dialogues and computation
occur before execution of the plan. Because both planning and execution take
time without requiring the same resources it is also possible to do them at the
same time. This means that the plan can be executed while it is still being
constructed. One way of doing this is my applying a window to DPCA*. A
window $w$ determines that agents will use the above algorithm to solve all
conflicts that occur within $w$ time steps from their current position. Agents
will not coordinate past the boundary of the window, solving conflicts that
happen beyond that border is deferred to a later point in time. Periodically
the agents will move their window and solve any new conflicts in the window.
Because agents only coordinate in the window it is not necessary for them to
plan a path past the window boundary as well. Instead agents can plan a path
for the next $w$ time steps so they get closer to their goal. To achieve this
the graph can be changed so that the nodes at the window boundary connect
directly to the goal node. This can be achieved by changing the cost function
between adjacent nodes $P$ and $Q$ \cite{silver2005}
\[
\text{\textsc{cost}(P,Q)} =
\begin{cases}
    0 & \text{if } P = Q = G, t < w \\
    \textsc{HeuristicDistance(P,G)} & \text{if } t = w \\
    1 & \text{otherwise}
\end{cases}
\]

Using the window spreads out the computation over the course of execution, but
it has other benefits as well. In large multi-agent systems the communication
between all agents may take a long time, by limiting the search using a window
there are only a limited number of agents that need to coordinate. This reduces
the initial planning time, as well as for each subsequent window. Agents that
are never in each other's window will never have to communicate with each other,
saving a lot of unnecessary communication and conflict detection overhead.
Windowing the search also has benefits in systems where agents can change their
destination during execution. Instead of recalculating the entire plan when
this happens, only agents within the window of the agent changing destination
have to update their plan. Agents that are not affected by the change in
destination do not have to update their plan. When there would be no window all
agents would have to recalculate and solve all conflicts again, even if they
would not need to update their plan, leading to wasted computational resources.

An overview of all proposed algorithms is given in \autoref{tbl:proposed}, the
categories shown are similar to those in \autoref{tbl:planning-overview}. All
methods are decoupled, not complete and do use priorities to ensure that agents
do not have conflicts. The meaning of communication has slightly changed, it
now restricts with which agents dialogues can be started.

\begin{table}
    \centering
    \caption{Comparison of proposed cooperative pathfinding algorithms. The
    communication and online columns are similar to that in
    \autoref{tbl:planning-overview}.}
    \label{tbl:proposed}
    \begin{tabular}{l|l|l|l}
        Algorithm & Na\"ive & Communication & Online \\ \hline
        PCA*   & Yes & All & No \\
        DPCA*  & No  & All & No \\
        WDPCA* & No  & Window & Yes \\
    \end{tabular}
\end{table}